\documentclass{llncs}
%\documentclass{article}
\usepackage{cite}

\title{The necessity of hypermedia RDF and an approach to achieve it}
\titlerunning{A hypermedia RDF approach}
\author{Kjetil Kjernsmo\inst{1}}
\institute{Department of Informatics,
Postboks 1080 Blindern,
0316 Oslo, Norway
\email{kjekje@ifi.uio.no}}


\begin{document}

\maketitle



\begin{abstract}
This paper will give an overview of the practical implications of the
HATEOAS constraint of the REST architectural style, and in that light argue why
hypermedia RDF is a practical necessity. We will then sketch a
vocabulary for hypermedia RDF using Mike Amundsen's H~Factor
classification as motivator. Finally, we will briefly argue that
SPARQL is important when making non-trivial traversals of Linked Data
graphs, and see how to a bridge between Linked Data and SPARQL may be
created with hypermedia RDF.
\end{abstract}

\section*{BRAINDUMP STATUS}

\section{Introduction}

%<> hm:can-be hm:put-to ;
% hm:can-be hm:deleted .

Mike Amundsen defines hypermedia types\footnote{\url{http://amundsen.com/hypermedia/}} as 
\begin{quote}
Hypermedia Types are MIME media types that contain native
hyper-linking semantics that induce application flow. For example,
HTML is a hypermedia type; XML is not.
\end{quote}
Furthermore, he defines a classification scheme called H~Factor as ``a
measurement of the level of hypermedia support and sophistication of a
media-type.'' The REST & WOA Wiki defines ``the Hypermedia
Scale''\footnote{\url{http://restpatterns.org/Articles/The_Hypermedia_Scale}},
where the categorization is based on capabilities for create, read,
update and delete operations.  Standing on it's own, RDF is a
hypermedia type, but only at the \textsf{LO} and \textsf{CL} levels,
and just an R~Type (read) on the Hypermedia Scale. We aim at improving
this situation.

Amundsen argues in a blog
post\footnote{\url{http://amundsen.com/blog/archives/1083}} that the
Semantic Web community should not pursue an API for RDF, but rather
work to make RDF a more powerful hypermedia type, like HTML or
Atom. He argues that a key factor in the success of the Web is that
messages not only contain data but also application control
information, and this is needed for the Web to scale.

We also note that some bloggers in the developer community, see
e.g.~\cite{sunsetonmvc}, is currently predicting a paradigm shift in
common practices, prompted by the trend towards richer clients. This
has caused a departure from the time-tested Model-View-Controller
pattern that has been the dominant paradigm in web development for
more than a decade.

Semantic Web services is likely to be an important source of data for
future applications, but for foreseeable future just one of many. A
key promise of Linked Open Data (LOD) in particular, and the Semantic
Web in general is the ability to integrate many data sources
easily. There are two key issues, first read-write operations must be
similar to how it is done with other hypermedia types to make it
possible to use generic code to minimize the effort required to
support RDF. Secondly, it requires relevant links and that the
resulting graph can be traversed by reasonable means.

While links are highly abundant across the LOD cloud, this paper will
argue that key links are missing to make it possible to traverse the
resulting graph and to enable read-write operations. Moreover, we will
argue that this shortcoming is due to that the community does not
adequately take into account the constraint known as ``Hypermedia as
the Engine of Application State'' (commonly abbreviated HATEOAS) from
the REST architectural style, see
\cite{Fielding_2000_Architectural-Styles}~Chapter~5.

In a read-only situation, the HATEOAS constraint requires that the
application can navigate from one resources to another using the
hypermedia links in the present resource \emph{only}, it should not
require any out-of-band information to do so. Thus, a RESTful protocol
should not require prior knowledge of a URI structure, but one may
define the protocol in terms of URI structure as long as the same
information can be gleened from the resources. Nor does it require
that all resources can be reached from any other resource. As such,
the constraint is not very strict, one could argue that as long as
there are some links, the protocol satisfies the HATEOAS constraint.

Since RDF is built on URIs, many of which can be dereferenced to
obtain further links, it lends itself well to RESTful protocols, but
it is debateable whether a protocol can be said to be RESTful if the
links doesn't enable any useful interactions. Importantly, if there is
to be such a thing as a RESTful read-write Semantic Web protocol,
there must be something in the RDF itself that can be used by
practical applications to write data. Therefore, whether the HATEOAS
constraint is satisfied must be judged on the basis of the practical
applications the protocol enables.

\section{Required links}

As noted in \cite{sunsetonmvc}, AtomPub has a single service endpoint,
and you can navigate to what you need from there. This motivates the
first discussion topic of this paper:

\begin{question}
Is a single service endpoint enough for Linked Data?
\end{question}

We note that the distributed graph structure of the LOD Cloud makes
this awkward: For every new data source encountered in a graph
traversal, a new service endpoint must be queried. Moreover, it would
be awkward if fine-grained access controls for writing is being used
to record permissions for all resources in a single service
description. It seems likely that a few triples attached to each
information resource is better suited in most cases.




