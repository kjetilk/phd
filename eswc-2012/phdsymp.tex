\documentclass{llncs}

\begin{document}
\title{Sharing statistics for SPARQL Federation optimization, with
  emphasis on benchmark quality}
\author{Kjetil Kjernsmo}
\institute{Department of Informatics,
Postboks 1080 Blindern,
0316 Oslo, Norway}



\maketitle

\email{kjekje@ifi.uio.no}

\begin{abstract}


\end{abstract}

\section{Introduction}

Query federation has been an active field for some time, but has until
the advent of the Semantic Web not been used in a highly diverse set
of endpoints, commonly they have been under the control of a single
institution. RDF has a triple-based data model for the Semantic Web,
and SPARQL is a standardized query language to query such data.

Query federation with SPARQL has attracted much attention
from industry and academia alike, and four implementations of basic
query federation were submitted to the SPARQL 1.1 Working Group as
input for the forthcoming
work\footnote{http://www.w3.org/2009/sparql/wiki/Feature:BasicFederatedQuery}. 
The basic query federation feature was
supported by a large number of group members, and the Last Call working
draft of the proposed standard was published on 17 November 2011.

While the basic feature set of the proposed standard can enable users
to create federated queries, it is not of great use as it requires
extensive prior knowledge of both the data to be queried and
performance characteristics of the involved query engines. Without
this knowledge, the overall performance is insufficient for any
practical applications.

I intend to investigate possible remedies to this problem by using
statistical techniques. 

Since the main objective of the proposed work is to create systems
that have sufficient performance for practical applications, it is of
paramount importance to have methodology that can falsify a
hypothesis about an implementation's performance.

In a federated regime, any query is likely to execute queries on
several different SPARQL implementations. Many of those are free
software so the algorithms they use could in principle be analyzed,
but in practice, this would be very time-consuming. Some
implementations may be undocumented or even trade secrets, thus
precluding any such analysis. It is therefore my intention to treat
the individual SPARQL implementations as ``black boxes'' and
exclusively evaluate the performance characteristics by empirical
means, aka ``benchmarking''.

However, I have found the current state of the art in benchmarking
lacking in its use of statistics, which motivates two distincts
directions of work: \emph{Statistical experimental planning and execution in
benchmarking} and \emph{statistical methods to optimize SPARQL queries
in a federated regime}.

\section{Problem Definition}

\subsection{In SPARQL Federation}

This part of the thesis addresses problems of query optimization in a
federated regime.

\subsection{In Benchmarking}

The contemporary problem in benchmarking is to distinguish
implementations when the measured difference is little or susceptible
to random noise.

\section{State of the Art}

\subsection{In SPARQL Federation}

\subsubsection{Technology}

I take the technology state of the art to be represented by the
current basic SPARQL 1.1 Federated Query Working
Draft\footnote{http://www.w3.org/TR/2011/WD-sparql11-federated-query-20111117/}. For
an academic treatment of the current specification, see
\cite{springerlink:10.1007/978-3-642-21064-8_1} and references therein.

\subsubsection{Science}

In \cite{springerlink:10.1007/978-3-642-21064-8_1}, the authors show
an optimization strategy based on execution order of different
algebraic elements. % TODO: wording here

In \cite{5337556}, it is shown how histograms can be computed to
assist the SemWIQ optimizer, written by the same authors.
% RDFStats

\subsection{In Benchmarking}

Numerous benchmarks have been developed for SPARQL, but
\cite{Duan:2011:AOC:1989323.1989340} showed that currently, most
benchmarks poorly represent the typical data and queries that is used
on the Semantic Web.

Most recently, \cite{mxro:Morsey2011DBpedia} addressed some of these
problems by using real data and real queries from DBpedia.

The problems addressed by these studies are almost orthogonal to the
problems considered by my proposed project. I have not to date seen
any work towards using contemporary statistical methods to evaluate
the performance of software, but I shall admit that my literature
study have been limited to RDF/OWL databases, and practical benchmarks
of databases, file systems, scientific software, etc. Thus, the
existence of relevant references in the deeper computer science
literature is a key issue I would appreciate discussing at the
Symposium.


\section{Proposed Approach and Methodology}

\subsection{In SPARQL Federation}

There are many possible approaches for this part of the thesis. At
this stage, it seems that use of selectivity estimation may be the
most feasible direction.

\subsection{In Benchmarking}

This part of the thesis seeks to use advances from statistical
experimental planning to improve accuracy and dependability of benchmarking.

\section{Conclusion}


\end{document}
