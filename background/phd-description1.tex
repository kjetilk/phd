\documentclass[a4paper,english,10pt]{article}
\usepackage{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{cite}

\title{Problem statement and suggested project outline}
\author{Kjetil Kjernsmo}

\begin{document}

\maketitle


Query federation has been an active field for some time, but has until
the advent of the Semantic Web not been used in a highly diverse set
of endpoints, commonly they have been under the control of a single
institution. RDF has a triple-based data model for the Semantic Web,
and SPARQL is a standardized query language to query such data.

Query federation with SPARQL has attracted much attention
from industry and academia alike, and four implementations of basic
query federation were submitted to the SPARQL 1.1 Working Group as
input for the forthcoming work. The basic query federation feature was
supported by a large number of group members, and the latest working
draft of the proposed standard was published on June 1st 2010 and is
expected to enter a Last Call review period shortly.

There is a very strong industrial use case for SPARQL query
federation, as it is a straightforward way to combine data from the
large number of SPARQL Endpoints. With the emergence of the Linked
Data Web, URIs serves as ``global keys'', and makes data combination
across data sources trivial if a working SPARQL query federation
engine can be used.

While the basic feature set of the proposed standard can enable users
to create federated queries, it is not of great use as it requires
extensive prior knowledge of both the data to be queried and
performance characteristics of the involved query engines. Without
this knowledge, the overall performance is insufficient for any
practical applications.

I intend to investigate possible remedies to this problem by using
statistical techniques. 

\section*{Paper 1: Conditional selectivity estimation on a single database}


An important technique for execution optimization is known as
``selectivity estimation''. This technique seeks to optimize the order
of which parts of the query is executed. In the greater database
literature, this has been widely studied, but the SPARQL specific
literature leaves many open questions.

An oft-cited paper is \cite{Stocker:2008:SBG:1367497.1367578}. In that
paper, the authors assume that the selectivity of RDF terms are
independent, admit that this assumption is easily violated and
continue to use a conditional estimate for the object node. This is
clearly flawed, and I have already started writing a first paper to
address this. Thus, it is intended that my first paper will address
open issues on selectivity estimation in the single-database
conditional case.  Several directions can be explored, possibly
involving Bayesian Networks, user configurable common SPARQL patterns,
estimation based on known ontologies, etc.

\section*{Paper 2: Empirical evaluation of implementations}

Since the main objective of the proposed work is to create systems
that have sufficient performance for practical applications, it is of
paramount importance to have methodology that can falsify a
conjecture about an implementation's performance.

In a federated regime, any query is likely to execute queries on
several different SPARQL implementations. Many of those are free
software so the algorithms they use could in principle be analyzed,
but in practice, this would be very time-consuming. Some
implementations may be undocumented or even trade secrets, thus
precluding any such analysis. It is therefore my intention to treat
the individual SPARQL implementations as ``black boxes'' and
exclusively evaluate the performance characteristics by empirical
means, aka ``benchmarking''.

I note that none of the established SPARQL benchmarks, or any other
benchmark I've seen, regard performance (however it is measured) as a
stochastic variable. It clearly is --- other things running on the
benchmark system, randomness in algorithms, unknown data structure,
etc. --- all contribute to random fluctuations in
performance. Consequently, none of the benchmarks use well-established
statistical methodology for hypothesis testing. They should, as
randomness could influence the conclusions drawn. Rectifying this
problem is a first step in the second paper I plan to write.

However, I wish to perform a much deeper investigation in the same
direction. In physical science and engineering, conventional wisdom
has been that you should only vary one variable at a time to study the
effects of that one variable. In medical science, this has been
abandoned several decades ago, thanks to advances in statistics. In
e.g. a case where the researcher administrates different treatments to
terminally ill patients, some of which may be painful or shorten their
lives, experimental economy is extremely important.

In SPARQL benchmarking, the state of the art is that one compiles data
which one hopes is representative for a wide selection of use cases,
and a select few queries. The performance is then measured. Recently,
\cite{Duan:2011:AOC:1989323.1989340} showed that the data used by all
existing benchmarks is far from representative, leaving many open
problems.

With this in mind, I plan to use ideas from statistical experimental
design to investigate whether it is possible to cover the entire
(realistic) parameter space, thus resolving the problem of choosing
hopefully representative data and queries. This would then be the main
topic of paper 2.

\section*{Paper 3: Conditional selectivity in the federated case}

In paper~1, I explored selectivity estimation as a technique for query
optimization. In a federated regime, selectivity estimation is
important because without it, large amounts of data may needlessly be
passed back and forth between different endpoints. However, the
federation engine has no way of estimating the selectivity of the
entire query since it has no record of the structure of the data.

The third paper will explore ways to remedy this situation, e.g. by
compiling statistics that may be exposed in a service description. In
particular, parameterized statistics may be useful. 

Finally, techniques developed in paper~2 will be used to evaluate the
efficiency of various techniques.

\end{document}
