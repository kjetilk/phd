%\documentclass[english,aspectratio=196]]{ifislide}
%\documentclass[english,print,aspectratio=169]{ifislide}
\documentclass[english,handout,aspectratio=169]{ifislide}
\usepackage{verbatim}
\usepackage{wrapfig}
%\setbeameroption{show notes}
\usepackage[utf8]{inputenc}
% Packages used specific for this lecture:

%\usepackage{bussproofs}
%\usepackage{textpos}

%\EnableBpAbbreviations
%% \usepackage{tikz}

%% \usetikzlibrary{arrows,shapes,mindmap}
%% \usetikzlibrary{decorations.pathmorphing}
%% \tikzstyle{resource}=[ellipse,draw=black!40,fill=blue!20,thick, font=\ttfamily]
%% \tikzstyle{blank}=[ellipse,draw=black!40,fill=white!40,thick, font=\ttfamily]
%% \tikzstyle{literal}=[rectangle,text centered,draw=black!40,fill=black!20,thick]
%% \tikzstyle{predicate}=[sloped,above,text centered,midway,font={\scriptsize\ttfamily}]
%% \tikzstyle{predicateb}=[left,midway,font={\scriptsize\ttfamily}]
%% \tikzstyle{class}=[rectangle,text centered,draw=black!40,fill=white,thick]
%% \usetikzlibrary{arrows,automata}


\newcommand{\typed}{\char`\^\char`\^}
\newcommand{\blank}{\char`\_}

\newcommand{\tuple}[1]{\left<#1\right>}
\newcommand{\inter}{\mathcal{I}}
\newcommand{\domain}{\mathop{\mathsf{dom}}}
\newcommand{\range}{\mathop{\mathsf{rg}}}

% set lecture number, date, title:
%\LectureNumber{13}
\LectureDate{23.10.2013}

\begin{document}

%\IfiTitleSlide     % inserts title frame

%\IfiTOCSlide       % inserts today's plan frame

\title[Statistical Design]{Introducing Statistical Design of Experiments to SPARQL Endpoint Evaluation}
\subtitle{}
\author{Kjetil Kjernsmo and John Tyssedal}
\maketitle

\section{Introduction} 

\begin{frame}{Objective}
  \begin{itemize}
  \item To introduce a path to critical practice of evaluations, that makes
use of contemporary statistical techniques, to establish a practice
that can be used to refute assertions on performance.
\item The focus is didactical, and the experiment we present is a toy
example.
\item To apply a well established method in statistics, rarely used in
  Computer Science, to SPARQL endpoint evaluation.

  \end{itemize}

\end{frame}

\begin{frame}{What's a benchmark?}

  \begin{itemize}
  \item Natural benchmarks.
  \item Benchmarking with broad and well-known workloads. 
  \item Use-case driven benchmarks.
  \end{itemize}

\end{frame}
\note{Natural benchmarks, query log-derived, DBPedia SPARQL Benchmark}
\note{If your queries are all fully known, by all means, run them}
\note{In most scientific relevant cases, no such assumptions can be
  made}
\note{What I will present will likely create artifical workloads}
\note{Use-case driven will seem artificial for everything else}


\begin{frame}{Problems with benchmarking}

\begin{itemize}
\item Large number of parameters to test for complex scenarios.
\item No structured approach to investigate flaws.
\item No meaningful summary of the overall performance.
\item Standardized benchmarks cannot test assertions outside of the
  standard.
\item Attempting to neutralize the effect of certain optimization
  techniques oversimplifies the test.
\end{itemize}
\end{frame}
\note{If you standardize hardware, you can't test claims about
  improved hardware. You'd need interactions too}
\note{Cache-buster is evil}

\begin{frame}{Design of Experiments}

  \begin{itemize}
  \item Pioneered by Fischer in the 1930s.
  \item Well-established in many fields of engineering, agriculture,
    medicine.
  \item Well-suited to manage very complex experiments.
  \item Requires parameterization of experiments.
  \end{itemize}
\end{frame}
\note{How many is familiar with DoE?}

\subsection{Key Concepts Design of Experiments}

\begin{frame}{Response variable}

% TODO Format well
   A \emph{response variable} is measured under various
    combinations of parameters.

For example:
\begin{itemize}
\item Throughput
\item Query execution time
\item Response time
\end{itemize}

\end{frame}

\begin{frame}{Factor}

Such parameters are called \emph{factor}s. 

For example:
\begin{itemize}
\item A concrete implementation
\item Hardware platform
\item Data heterogeneity
\item Number of triples in the store
\item Absence or presence of certain language features
\item Order of experiments
\item Tuning parameters
\item Concurrency
\end{itemize}

\end{frame}

\begin{frame}{Levels}

For each factor, a range of possible values are fixed. These values
are called \emph{levels}.

\begin{block}
  For example:
  \begin{itemize}
  \item For implementation, 4store or Virtuoso.
  \item For number of triples, the levels could be 1 or 2 MTriples.
  \item For language features, the levels could be \textsf{SELECT} and \textsf{CONSTRUCT}
  \end{itemize}
\end{block}
Levels may be continuous, discrete, different instances of a
class, etc.

\end{frame}

\begin{frame}{Design Matrix}

% latex table generated in R 2.15.1 by xtable 1.5-6 package
% Sat Oct  5 22:16:51 2013
\begin{table}[ht]
\begin{center}
\begin{tabular}{r|ccc}
  \hline
 & Implement & TripleC & Union \\ 
  \hline
1 & 2 & 1 & 2 \\ 
  2 & 2 & 2 & 2 \\ 
  3 & 2 & 1 & 1 \\ 
  4 & 1 & 1 & 1 \\ 
  5 & 2 & 2 & 1 \\ 
  6 & 1 & 2 & 1 \\ 
  7 & 1 & 2 & 2 \\ 
  8 & 1 & 1 & 2 \\ 
   \hline
\end{tabular}
\end{center}
\end{table}


\end{frame}
\note{There are 3 factors, 8 experiments, which is $2^3$}

\begin{frame}{Factorial experiments}

  \begin{itemize}
  \item Full factorial experiments:
    \begin{itemize}
    \item 2 levels give $2^n$ combinations (\emph{runs}), where $n$ is
      the number of factors.
    \item 3 levels give $3^n$ runs, etc.
    \end{itemize}
  \item Fractional factorial experiments:

    \begin{itemize}
    \item When experimental economy is important,
    \item DoE theory offers extensive facilities for running a
      fraction of the runs ($2^{n-1}$ etc).
    \item The price is of smaller experiments is explanatory power.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Main effects}

\emph{Effects} describe the influence of the levels on the response.

The the \emph{main effect}: For a factor $A$ with two levels, we let
$a_1$ and $a_2$ be the average response of all $2^{n-1}$ measurements
with $A$ at level 1, and 2, respectively.  The main effect of $A$ is
then defined as $a_2 - a_1$.

For example: 

For each implementation, average all the responses. Then, the main
effect of the implementation is the difference between them.

\end{frame}

\begin{frame}{Interaction effects}

\emph{Interaction effects} for two factors $AB$ are defined
by comparing averages for equal versus non-equal levels of $A$ and
$B$. 

For example:

For each implementation, find the averages for each dataset size, the
interaction effect is % TODO: Clear example.


In practice, Quite Easily Done using linear regression.
\end{frame}
\note{Interaction effects may be complex, like one implementation is
  better on CONSTRUCT queries, on small datasets}
\note{We still need to understand which effects are important and
  significant, we do that in the discussion of our experiment}


% SECTION

\section{Experiments}

\begin{frame}{Constraints on scope of experiment}

Above all: Easy to understand for newcomers to DoE!

\begin{itemize}
\item Just 2 levels.
\item Handful of illustrative factors.
\item Analysis that illustrates key concepts.
\item Straightforward to program and reproduce.
\item Artificial performance differences.
\end{itemize}

\end{frame}

\begin{frame}{Choices to meet these constraints}

  \begin{itemize}
  \item Response variable: Time from DNS lookup finishes to endpoint
    has delivered a full response, measured by \texttt{curl}.
  \item We don't compare different implementions, we compare the
    performance before and after some change.
  \item Query engine: \texttt{4store} where we insert \textsf{sleep}
    statements in the join function on one level and language matching
    function on the other. 
  \end{itemize}

\end{frame}

\begin{frame}{Factors and levels}
  \begin{description}
  \item [``Implement''] The implementation under evaluation.
  \item [``TripleC''] 1 or 2 MTriples from the DBPedia SPARQL
    Benchmark.
  \item [``Machine''] Software and hardware platform, one smaller
    machine with fast SSD and one larger with slower disks in RAID1.
  \end{description}
\end{frame}

\begin{frame}[fragile]{The Basic Graph pattern factor}
  \begin{description}

  \item [``BGPComp''] Two different basic graph patterns with varying
    complexity.
  \end{description}

  \begin{center}\small
    \begin{tabular}{|@{~~}p{0.40\textwidth}|@{~~}p{0.40\textwidth}|}
      \hline
      \textbf{Level 1} & \textbf{Level 2} \\[-2ex] 
      \begin{verbatim}
?s  rdfs:label ?l1 ;
    ?p1 ?o1 .
?o1 dbo:populationTotal ?l2 .
      \end{verbatim}
      & 
      \begin{verbatim}
?s  rdfs:label ?l1 ;
    ?p1 ?o1 .
?o1 dbo:populationTotal ?l2 .
?s foaf:page ?o2 ;
   dbpprop:subdivisionName ?o3 .
?o3 skos:subject ?o4 ;
   dbpprop:seat ?o5 ;
   a ?c1 .
\end{verbatim} 
\\      \hline
    \end{tabular}
  \end{center}

\end{frame}

\begin{frame}[fragile]{Absence or presence factors}
  \begin{description}
  \item [``Union''] Absence or presence of a \textsf{UNION} pattern.

    \begin{verbatim}
{ ?o1 dbpprop:longd ?long ;
      dbpprop:latd  ?lat .
} UNION {
  ?o1 geo:long ?long ;
      geo:lat ?lat . }
\end{verbatim} 

  \item [``Lang''] Absence or presence of a \textsf{langMatches}
    filter.

\begin{verbatim}
FILTER langMatches( lang(?l1), "fr" ) 
\end{verbatim} 


  \item [``Range''] Absence or presence of a filter with a larger-than
    operator.

    \begin{verbatim}
FILTER (?l2 > 800000)
\end{verbatim} 

  \item [``Optional''] Absence or presence of an \textsf{OPTIONAL}
    pattern.
    \begin{verbatim}
OPTIONAL { ?o1 foaf:homepage ?o6 . }
\end{verbatim} 

  \end{description}
\end{frame}
\note{Implemented in R, using packages \texttt{DoE.base} and \texttt{FrF2}.}
\note{Two experiment machines, one machine running queries}
\note{No warm-up, no cache busting}
\note{256 experiments in full factorial, no replications, compare
  favorably to benchmarks}

\subsection{Full Factorial Experiment}

\begin{frame}{Full normal plot}
  \begin{minipage}{0.49\textwidth}
    \includegraphics[width=\textwidth]{fullnormal.pdf}
  \end{minipage}
  %
  \begin{minipage}{0.49\textwidth}\small
    \vspace{-2ex}\qquad
    \begin{tabular}{rr}
      \hline
      \textbf{Factors} & \textbf{Effect}  \\ 
      \hline
      Implement & $-$21.27 \\ 
      Implement:Optional & $-$11.49 \\ 
      Implement:Union & $-$6.21 \\ 
      Implement:TripleC:Lang1 & 4.12 \\ 
      TripleC:Lang & 4.20 \\ 
      Implement:TripleC & 4.32 \\ 
      Implement:BGPComp & 4.89 \\ 
      Lang:Union & 5.16 \\ 
      Implement:BGPComp:Lang & 5.16 \\ 
      BGPComp:Lang & 5.25 \\ 
      Implement:Lang:Union & 5.75 \\ 
      TripleC & 7.06 \\ 
      Implement:Lang & 7.73 \\ 
      Lang & 8.62 \\ 
      Optional & 11.30 \\ 
      Union & 17.18 \\ 
      \hline
    \end{tabular}
  \end{minipage}
\end{frame}

\note{Unreplicated, so we don't have a standard error, so Lenth used
  a restricted subset the median of the effects to create a Pseudo
  Standard Error}
\note{Don't worry about the axes}
\note{Yes, the Implementation is better, we knew that, joins are
  naturally strong}
\note{``Union'', ``Optional'' and ``Lang'' demanding things}
\note{``BGPComp:Lang'' and ``Lang:Union'' interactions might be due to
  that many more triples need to be searched for a language tag in one
  of the levels of the interacting factors.}
\note{But what about ``Implement::TripleC''?}
\note{We want to do a hypothesis test}
\note{Two factors do not contribute significantly to the variation
  ``Range'' and ``Machine''}

\begin{frame}{Hypothesis tests}

Hypothesis formulation:
  \begin{itemize}
  \item $H_0$: The new implementation is no better than the old.
  \item $H_1$: The new implementation is better than the old.
  \end{itemize}

Classifying factors:
  \begin{itemize}
  \item ``Range'' and ``Machine'' are called \emph{inactive factors}.
  \item ``BGPComp'', ``Lang'', ``Optional'', ``Union'' and ``TripleC''
    are called \emph{environmental factors}.
  \item ``Implement'' is called a \emph{control factor}.
  \end{itemize}

\end{frame}
\begin{frame}{Hypothesis tests}

\begin{itemize}
\item Average over all the 32 level-combinations of the environmental
  factors. 

% latex table generated in R 2.15.1 by xtable 1.5-6 package
% Tue Oct  8 14:51:28 2013
\begin{table}[ht]
\begin{center}
\begin{tabular}{rlll|r}
  \hline
 & Implement & Machine & Range & Response \\ 
  \hline
1 & 1 & 1 & 1 & 33.47 \\ 
  2 & 2 & 1 & 1 & 11.82 \\ 
  3 & 1 & 2 & 1 & 32.16 \\ 
  4 & 2 & 2 & 1 & 11.56 \\ 
  5 & 1 & 1 & 2 & 33.97 \\ 
  6 & 2 & 1 & 2 & 12.46 \\ 
  7 & 1 & 2 & 2 & 32.90 \\ 
  8 & 2 & 2 & 2 & 11.60 \\ 
   \hline
\end{tabular}
\end{center}
\end{table}

\item May create a one-sided two-sample t-test with 4 values for each of the levels.
\item Lends support to $H_1$ with a high probability, $p=1.16 \cdot
10^{-07}$.

\end{itemize}

\end{frame}
\note{The paper shows how similar testing can be done to investigate
  when the new implementation fails.} 

\subsection{Fractional Factorial Experiments}

\begin{frame}{Experimental Economy}

  \begin{itemize}
  \item Full factorial experimental goes as $2^n$.
  \item SPARQL Endpoint evaluation is inherently complex, with many
    possible factors.
  \item May reduce the size of the experiment with Fractional
    Factorial Experiments.
  \item The cost is explanatory power due to \emph{aliasing}.
  \item E.g. we cannot tell the difference of an effect of
    ``TripleC::BGPComp'' from ``Machine::Range''
  \item Easy in R to declare which effects must not be aliased.
  \item We have made two designs: One 32-run and one 64-run.
  \end{itemize}
  
\end{frame}
\note{ That is to say, a detected increase in
run time from larger Basic Graph Patterns for large databases, can
also be explained by a less powerful machine that is worse at
evaluating FILTER clauses with ranges. }

\begin{frame}{32-run experiment}
\begin{figure}[ht!]
  \centerline{%
    \includegraphics[height=0.85\textheight,width=.9\textwidth]{frac32normal.pdf}}
  \label{fig:frac32normal}
\end{figure}
 
\end{frame}
\note{The total variance is great, due to few runs, so few conclusions
  can be drawn}
\note{Implementation is good, and Union is hard}
\note{In the paper, we also do a hypothesis test that returns  $p =
  0.00098$. Still very low}
\note{Very rough conclusions; useful in a CI system}

\begin{frame}{64-run experiment}
\begin{figure}[ht!]
  \centerline{%
    \includegraphics[height=0.85\textheight,width=0.96\textwidth]{frac64normal.pdf}}
\end{figure}


\end{frame}
\note{Have two Lenth criterions, $\alpha=0.15$ and crosses at
  $\alpha=0.05$. ($\alpha$ is the probability of rejecting $H_0$ when
  it is true)}

\begin{frame}{Analysis of 64-run experiment}

  \begin{itemize}
  \item Find most of the same significant effects as the full experiment.
  \item However, we see that ``Implement:TripleC'' emerges only for
  $\alpha=0.15$.
  \item ``Machine'', ``TripleC'' and ``Range'' are inactive, we can
    perform hypothesis test as above, and find $p = 5.9 \cdot 10^{-6}$.
  \end{itemize}
\end{frame}
\note{We see that ``Implement:TripleC'' emerges only for
  $\alpha=0.15$, which is important to better in real studies.}
\note{We have shown that how the experiment could be set up, we have
  shown the analysis and a hypothesis test.}
\note{Should this simplistic experiment stand up to scrutiny?}

\subsection{Tearing it all down}

\begin{frame}{Fractional experiment with more data}
\begin{figure}[ht!]
  \centerline{%
  \includegraphics[height=0.85\textheight,width=.9\textwidth]{frac64hugenormal.pdf}}
\end{figure}
  
\end{frame}
\note{``Machine'' is a broad factor, good idea to group to manage
  complexity, can be broken down later}
\note{``TripleC:Machine'' and ``TripleC'' highly significant, implies
  the factors were wrongly set.}
\note{This invalidates the three preceeding experiments. We got strong
indications early on.}

\section{Discussion}

\begin{frame}{Linearity and choice of levels}
  \begin{itemize}
  \item 2-level experiments can only model linear effects.
  \item Choice of levels may be critical.
  \item If response is known to be non-linear, using more levels must be considered.
  \end{itemize}
  
\end{frame}
\note{2-level good enough for identifying effects, insufficient as
  statistical model}

\begin{frame}{The role of randomization}
  \begin{itemize}
  \item We have allowed us to disregard the effect of caching,
    warm-up-runs, etc.
  \item This is different from neutralizing the effect!
  \item They are now ``lurking variables''.
  \item They contribute to the overall unexplained variance.
  \item Unexplained variance should be kept to a minimum.
  \item Time-dependent or order-dependent factors may be required.
  \end{itemize}
\end{frame}
\note{Even though we know caching is important}
\note{Caching is good practice, shouldn't be neutralized. Warm-up may
  not be permissible in real-time scenarios}
\note{Variance can obscure problems like ``Implement:TripleC''}
\note{most problematic cases are those that are
covered neither by the broad factors, nor the lurking variables, or
any of the specific factors. Invalidated by absence of language
features, such as solution modifiers.}

\section{Future Work}

\begin{frame}{Choice of factors}

  \begin{itemize}
  \item Different strategies must be tried, open field.
  \item Parameterization is very important.
    \begin{itemize}
    \item Data heterogeneity, skewed distributions, etc.
    \item Parameterizing SPARQL queries, see e.g. SPLODGE by Görlitz
      et al.
    \item Parameterizing SPARQL queries using the grammar pragmatically?
    \end{itemize}
  \end{itemize}
  
\end{frame}
\note{Optimization parameters, hardware characteristics}

\begin{frame}{Other important issues}

  \begin{itemize}
  \item Comparing completely different SPARQL implementations.
  \item Ensuring that small and efficient experiments provide enough
    details to assess the soundness of the experiment.
  \item This paper scratches the surface of DoE, Orthogonal Arrays is
    a more general formalism.
  \item This topic is also interesting for progress beyond the
    state-of-the-art in statistics.
  \end{itemize}
  
\end{frame}

\section{Conclusion}

\begin{frame}
We saw
  \begin{itemize}
  \item ... an experimental setup using DoE.
  \item ... how the analysis pointed out the important effects.
  \item ... how we got a comprehensive view of the experiment.
  \item ... how hypothesis tests could be formulated.
  \item ... how 2-level experiments can determine significant effects,
    even though it is not good enough for modelling.
  \item ... how more economic experiments can be designed, and noted
    their limitations.
  \item ... finally how the experiment could be shown to be flawed.
  \end{itemize}
\end{frame}

\begin{frame}{Questions to ask}

\begin{enumerate}
\item Are there factors that cover all realistic features?
\item If not, are they adequately covered by randomization?
\item If so, would the variance resulting from randomization obscure
  factors that could provide clues that the levels are wrongly set?
\item By carefully examining interactions with ``Implement'', are
  there any that are unaccounted for, and that could point out wrongly
  set levels?
\end{enumerate}

  
\end{frame}

\begin{frame}{What's a worthy result?}
  \begin{itemize}
  \item I have not made this a primary focus of my work.
  \item Even though I think I should.
  \item 3000 full-time researchers to construct the ATLAS experiment
    at CERN.
  \item Improvement in experimental methodology should be a worthy result.
  \end{itemize}


\end{frame}


\begin{frame}{Thank you!}

  \begin{itemize}
  \item Code and instructions at Github:
    \url{https://github.com/kjetilk/doe-sparql}.
  \item Happy to help getting it to run!
  \end{itemize}

\end{frame}


\end{document}
