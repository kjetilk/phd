\documentclass[12pt, draft]{article}
\usepackage{cite}
\usepackage[utf8]{inputenc}

\newcommand{\rdfterm}[1]{\texttt{#1}}
\newcommand{\todo}[1]{\ensuremath{^{\textrm{\tiny{TODO}\normalsize}}}\footnote{\textbf{TODO:}~#1}}
\newcommand{\sel}[1]{\ensuremath{\mathrm{sel}\left(#1\right)}}

\title{Conditional selectivity for triplestores}

\author{Kjetil Kjernsmo}

\begin{document}
\maketitle

\section*{Status of this document}

This is currently at braindump status. Do not distribute without the
permission of the author.

\begin{abstract}
  This paper explores selectivity estimation for single triple
  patterns in SPARQL queries. In this paper we see how the common
  assumption of independence of the selectivity of RDF terms can be
  abandoned. We proceed to extend SPLENDID\cite{splendid} using the
  new formalism and demonstrate how VoID data descriptions\cite{void}
  can be further exploited in the conditional regime to optimize join
  order. Finally, we will explore how selectivity can be determined
  exactly when a SPARQL query is executed on a fully indexed
  triplestore, such as
  Hexastore\cite{Weiss:2008:HSI:1453856.1453965}. Finally, we will
  suggest further directions for selectivity estimation in the
  conditional regime.

\end{abstract}

\section{Introduction}

Several authors have studied the use of selectivity estimation for
optimizing SPARQL query execution plans, both in the context of Basic
Graph Patterns \cite{Stocker:2008:SBG:1367497.1367578} and in more
general cases. \todo{more references. OptARQ? Some go into conditional
regimes, actually.}

The above authors assume that the selectivity of RDF terms are
independent, admit that this assumption is easily violated and
continue to use a conditional estimate for the object node.

It is easy to point out cases where the independence assumption is
unlikely to hold: If a predicate is \rdfterm{rdf:type}, then only
classes are likely objects, and their frequency would likely be
different from e.g. literals. Moreover, it is easy to see when triples
in a basic graph pattern are likely to be dependent: If one triple has
\rdfterm{rdf:type} as predicate and \rdfterm{foaf:Person} as object,
the next triple is much more likely to contain the very
common predicate \rdfterm{foaf:name} than the esoteric
\rdfterm{foaf:dnaChecksum}.

\section{Related Work}

\cite{splendid}, \cite{wodqa} \todo{write this}.

\section{Conditional selectivity}\label{sec:cond}

Previous authors have taken selectivity as analogous to the
probability of matching a SPARQL term (RDF Term or variable) with an
RDF term in the data or a SPARQL triple pattern with a triple in the
data.  For a triple, $<S, P, O>$ the selectivity is the intersection
of the selectivity of each term.

From elementary statistics, we know that the intersection probability
can be written as
\begin{eqnarray}
Pr(A_1 \cap A_2  \cap \ldots \cap A_n) &=& 
  Pr(A_n | A_1 \cap A_2  \cap \ldots \cap A_{n-1}) \nonumber\\
  &&\cdot Pr(A_{n-1} | A_1 \cap A_2  \cap \ldots \cap A_{n-2}) \cdot \ldots \nonumber\\
  && \cdot Pr(A_2 | A_1) \cdot Pr(A_1) ,
\end{eqnarray}
where the $|$ symbol is read as ``given'', e.g. ``given a predicate
\rdfterm{rdf:type} what is the probability that the object is \rdfterm{foaf:Person}?''

Analogously\todo{anybody good at arguing this mathematically?}, the
conditional selectivity for a triple pattern $T$ can be written as 
\begin{equation}\label{eq:sel}
\sel{T} = \sel{S \cap P \cap O} = \sel{O | S \cap P} \cdot \sel{P | S}
\cdot \sel{S} . 
\end{equation}
We note that intersection is commutative, thus similar
relations can be shown for each permutation of terms.

Finally, note that for variables, the selectivity will always be
unity, since it will match all possible RDF terms.

\subsection{Example}\label{sec:example}

Consider the following RDF graph, expressed in Turtle with base URI
and namespace declarations omitted for brevity:

\begin{verbatim}
</alice> a foaf:Person ;
         foaf:firstName "Alice" ;
         rel:spouseOf </bob> .
</bob>   a foaf:Person ;
         foaf:firstName "Bob" ;
         foaf:based_near </place> .
</place> rdfs:label "Our House" .
\end{verbatim}

A very simple example is to find the selectivity for the triple pattern
\begin{verbatim}
?person a foaf:Person .
\end{verbatim}
We can easily see that the correct answer is $\sel{T} = 2/7$ since two
out of the 7 triples match the pattern. To see how Eq.~\ref{eq:sel} is
used, we note that $\sel{S} = 1$ since it is a variable. $\sel{P | S} =
2/7$ since the predicate matches the two occurences of
\rdfterm{rdf:type} and the subject variable doesn't influence
this. Finally, $\sel{O | S \cap P} = 1$ since the only two occurences
of \rdfterm{foaf:Person} occurs in the same triples as
\rdfterm{rdf:type}. Thus, we arrive at the expected result.

In a slightly harder example:
\begin{verbatim}
?person foaf:firstName "Bob" .
\end{verbatim}
We still have $\sel{S} = 1$ as above, and there are still two
predicates that match, so $\sel{P | S} = 2/7$, but only half of those
match the literal, so $\sel{O | S \cap P} = 1/2$, giving us the
expected $\sel{T} = 1/7$.

\section{Exploiting VoID descriptions}

In SPLENDID\cite{splendid} the authors showed how statistics exposed
using the VoID data description vocabulary\cite{void} could be
exploited for query optimization. The authors made the assumption that
subjects and objects were uniformly distributed and independent from
the predicate. The present paper extends their work by relaxing these
assumptions.

In section~\ref{sec:cond}, we derived an equation for conditional
selectivity, i.e. RDF terms are not independent of each
other.
 
In the following, we shall have to introduce to more elaborate
notation to make sure we maintain control of bounded and unbounded
terms. We denote a bounded term with a lowercase letter, $s$
for a subject, $p$ for a predicate and $o$ for object, and variables
are denoted by a question mark, $?$. For example, $p =
\rdfterm{rdf:type}$. We also adopt SPLENDIDs convention of denoting
the number of all triples in certain data source $|d|$ (which can also
be found as the \rdfterm{void:triples} of the dataset).

\subsection{Parts that can be computed}

There will be a number of different equations that arises from using
the commutative property of intersections, and some parts of these
equations is possible to compute from VoID descriptions.

\subsubsection{Equalities}

We have already noted the most trivial case, for variables we have:

\begin{equation}\label{eq:selvar}
\sel{S = ?} = \sel{P = ?} = \sel{O = ?} = 1 .
\end{equation}

We note that VoID includes the concept of \emph{property partitions}
(see section~4.5 in \cite{voidnote}): ``A property-based partition
contains only those triples of a dataset that use a particular
predicate.'', and since a partition is itself a dataset, the same
statistical properties can be applied, such as \rdfterm{void:triples},
\rdfterm{void:distinctSubjects} and \rdfterm{void:distinctObjects}.

In the case where the predicate is known, we have
\begin{equation}\label{eq:selPp}
 \sel{P = p} =
   \frac{\rdfterm{void:propertyPartition/void:triples}}{|d|} ,
\end{equation}
where the notation is inspired by SPARQL 1.1 Property Paths, for
example the relevant part of a VoID description for the second example
in section~\ref{sec:example} would be:
\begin{verbatim}
 </dataset> a void:Dataset ;
            void:propertyPartition [
                void:property foaf:firstName;
                void:triples 2 .
            ]
\end{verbatim}
where $p = \rdfterm{foaf:firstName}$.


In the case where there is a given predicate but the subject is a
variable, we can use the \rdfterm{void:distinctSubjects} property:
\begin{equation}\label{eq:selSvPp}
 \sel{S = ? | P = p} =
   \frac{\rdfterm{void:propertyPartition/void:distinctSubjects}}{\rdfterm{void:propertyPartition/void:triples}} ,
\end{equation}

The above are the parts of the equations that can be computed directly
from the VoID description, and in the next section we shall see how
they can be exploited.

\subsubsection{Inequalities}

As noted in the abstract, the goal is to establish join order for
optimization. For this to be successful, it is not critical to be able
to estimate the selectivity in all cases. It may also suffice to
establish that the selectivity of one triple pattern is greater or
smaller than another, they can then be ordered.

First, in the case where the object is a variable, there may be multiple
objects for each predicate in the partition, so we can only say:
\begin{equation}\label{eq:selOvPp}
 \sel{O = ? | P = p} \ge
   \frac{\rdfterm{void:propertyPartition/void:distinctObjects}}{\rdfterm{void:propertyPartition/void:triples}} .
\end{equation}
We note that OWL cardinality constraints may constrain this problem
and that \rdfterm{void:vocabulary} may be used to find the
corresponding ontology.

 
\subsection{Triple pattern cases}

We shall now systematically go through different triple patterns and
see how the selectivity can be derived from VoID descriptions per the
most recent vocabulary\cite{voidnote}:



\paragraph{Subject and object unbound, predicate bound}

By using Eq.~\ref{eq:sel} and swapping $S$ and $P$, we have 
\begin{equation}\label{eq:selsuobunpb}
\sel{T_{\{?~p~?\}}} = \sel{O = ? | P = p \cap S = ?} \cdot 
\sel{S = ? | P = p} \cdot
\sel{P = p} . 
\end{equation}
where we recognize Eqs.~\ref{eq:selSvPp}~and~\ref{eq:selPp} as the
last two parts. The first part, $\sel{O = ? | P = p \cap S = ?}$ must
be computed some other way, by employing heuristics or by using more
advanced statistical methods. 



\paragraph{Subject unbound, object and predicate bound}

This case is similar to the above, and we can write 
\begin{equation}\label{eq:selsuunobpb}
\sel{T_{\{s~p~?\}}} = \sel{O = ? | P = p \cap S = s} \cdot 
\sel{S = s | P = p} \cdot
\sel{P = p} . 
\end{equation}
We note that we can't find the first two parts in the VoID
description\todo{2nd part smaller than a fraction of distinctSubjects?}, but we also note with interest that the first part shows
that only the marginal distribution of objects is needed to estimate
this part.

\paragraph{Subject unbound, class bound}

The selectivity can be found directly in the case of a given class,
i.e. predicate \rdfterm{rdf:type} or $P = a$ and $O = c$, we can use
\rdfterm{void:classPartition} (also defined in section~4.5 in
\cite{voidnote}) to find the selectivity of the triple
pattern\footnote{The specification is unclear at this point, as it
 mentions the concept of entities, in which case
 \rdfterm{void:entities} might be used rather than
 \rdfterm{void:triples}, but we believe that this is the correct usage}:
\begin{equation}\label{eq:selSvPaOc}
 \sel{T_{\{?~a~c\}}} =
    \frac{\rdfterm{void:classPartition/void:triples}}{|d|} .
\end{equation}

\subsection{Interesting distributions}

Uniform distributions have no impact on join order\todo{argue}.
\todo{Use parameterized stats for datatype properties?}

\subsection{Suggested additions to the VoID vocabulary}

Allthough a careful estimate of the selectivity in situations where we
have e.g. $\sel{O = ? | P = p \cap S = ?}$ would require a two
dimensional distribution function, the most significant impacts on
join order is when the distribution is highly skewed\todo{argue}. A
hint to the optimizer in such cases could be achieved by the addition
of properties like \rdfterm{void:mostFrequentObjects},
\rdfterm{void:mostFrequentSubjects},
\rdfterm{void:leastFrequentObjects} and 
\rdfterm{void:leastFrequentSubjects} to property
partitions.\todo{mention the dc:language case in Sublima?}

\section{Exact selectivity for fully indexed stores}

Some triplestores fully index all terms. A prominent example is the
Hexastore that was first described in
\cite{Weiss:2008:HSI:1453856.1453965}, which sought to exploit a key
strength of the RDF triple model by using six-way indices for
efficient lookup.

A Hexastore contains the six indices \textsf{spo}, \textsf{pso},
\textsf{osp}, \textsf{sop}, \textsf{pos} and \textsf{ops}. Each index
has the following structure, taking \textsf{spo} as an example: ``A
subject key $s_i$ is associated to a sorted vector of $n_i$ property
keys, $\{p_1^i , p_2^i , \ldots , p^i_{n_i} \}$. Each property key $p_j^i$
is, in its turn, linked to an associated sorted list of $k_{i,j}$
object keys.''\cite{Weiss:2008:HSI:1453856.1453965}, section~4.1.

Let us return to the example in section~\ref{sec:example}: We have
$s_1 = \texttt{key-for-alice}$ and $i=2$. Further, $p_1^1 =
\texttt{key-for-foaf:firstName}$, $p_2^1 = \texttt{key-for-rdf:type}$ and $p_3^1 =
\texttt{key-for-rel:spouseOf}$ and $n_1 = 3$. For each predicate, there is only
one object, so $k_{1,1} = 1$ and $o_{1_{1,1_1}}^{1,1_1} = \texttt{key-for-Alice-literal}$.

The pattern that emerges is that since the index for the predicate is
already dependent on the match for the subject, the conditional
selectivity depends only on the number of matches of a term and the
total number of keys in the index. Thus, the selectivity can be
computed \emph{exactly} based on the data only. The selectivity of a
query then depends only on what indices are used. 

Formalizing this notion, we first define a function $cm(x)$ which
returns the number of matches of a given key $x$\todo{argue the
  term-key-connection}. 

Then, 
\begin{equation}
\sel{S = s_i} = \frac{cm(s_i)}{i} ,
\end{equation}
\begin{equation}
\sel{P = p_{n_i}^i|S = s_i} = \frac{cm(p_{n_i}^i)}{n_i}
\end{equation}
and
\begin{equation}
\sel{O = o_{k_{i,n_i}}^{i,n_i} |S = s_i \cap P = p_{n_i}^i} =
\frac{cm(o_{k_{i,n_i}}^{i,n_i})}{k_{i,n_i}} .
\end{equation}
\todo{surely needs more work}

With this, it should be possible to store the selectivity along with
the indices in a Hexastore.

We also note that exposing a suitable VoID description should be cheap
using the above formalism.

\section{Further work on conditional selectivity}

\todo{this section}

\bibliographystyle{plain}
\bibliography{selectivity}



\end{document}
