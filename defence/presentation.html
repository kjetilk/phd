<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <base href="http://dev.kjernsmo.net/reveal.js/"/>
    <!-- base href="http://0.0.0.0:8000/"/ -->
    <title>SPARQL on the Open, Decentralised Web</title>
    
    <meta name="description" content=""/>
    <meta name="author" content="Kjetil Kjernsmo"/>
    
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"/>
    
    <link rel="stylesheet" href="css/reveal.css"/>
    <link rel="stylesheet" href="css/theme/black.css" id="theme"/>
    
    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css"/>

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
    
    
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
       <style>
         blockquote { text-align: justify }
         blockquote footer { text-align: right }
         pre { padding : 1em; background-color: #444 }
         td.cd { background-color: #366 }
         td.ld { background-color: #636 }
       </style>
  </head>
  
  <body>
    
    <div class="reveal">
      
      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
	<section>
	  <h1>SPARQL on the Open, Decentralised Web</h1>
	  <p>
	    Kjetil
            Kjernsmo, <a href="http://kjetil.kjernsmo.net/">http://kjetil.kjernsmo.net/</a>,
            <a href="https://twitter.com/KKjernsmo">@KKjernsmo</a>.
          </p>
          <p>
            Defence for the Degree of <span lang="la">Philosophi√¶ Doctor</span>.
          </p>
        </section>
 
        <section>
          <h2>The Philosophical Take</h2>
          <ol>
            <li class="fragment">Motivation</li>
            <li class="fragment">Preliminaries</li>
            <li class="fragment">Solutions</li> 
           <li class="fragment">Contributions</li>
          </ol>
        </section>

        <section>
	  <h3>The Problem</h3>
	  
	  <p style="border: solid; padding: 1em 2em; text-align: justify">
	    To achieve a Semantic Web where anyone can say anything
	    about anything, and where everyone is enabled to analyse
	    data that have been contributed, there is a difficult
	    balance between centralising infrastructure and
	    decentralising it, and between processing on clients and
	    servers.
            </p>
	  <aside class="notes">
	    TODO: Semweb needs to be explained, SPARQL too?
	  </aside>
	</section>
	
	<section>
	  <h3>There are Social Issues</h3>
            
	  <ul class="fragment">
	    <li class="fragment">The "Echo Chamber" problem, getting information into
	      closed minds</li>
	    <li class="fragment">Concentration of power</li>
	    <li class="fragment">Limits the research on platforms</li>
	    <li class="fragment">Doesn't provide a platform for everyone</li>
	    <li class="fragment">Limits the influence people have of their own data.</li>
            </ul>
	  
	  <aside class="notes">
	    2. opponent coauthored a paper titled "Learning from the
	    History of Distributed Query Processing" in a workshop
	    that the 1. opponent chaired, where a centralised
	    solution was proposed, in response to lessons learned
	    over decades of research on distributed
	    systems. However, the main reasons for decentralisation
	    aren't technical, they are social.
	  </aside>
	  
	</section>
	
	<section>
	  <h3>Decentralisation</h3>
	  <img src="http://folk.uio.no/kjekje/2016/defence/decentralised.svg" 
	    alt="Centralisation vs decentralisation"/>
            
            <aside class="notes">
              <ul>
                <li>Not the same as in the Trial Lecture. TimBL,
		  Wikipedia</li>
                <li>Internally in central node may be distributed</li>
                <li>Fully distributed where no node has a privileged
		  position.</li>
                <li>We don't need to go to the extreme fully
                  distributed situation to realize the social
                  benefits. Pragmatically see what we can do.</li>
              </ul>
            </aside>
	    
	</section>
	
	<section>
	  <h3>Real Life Problems</h3>

	  <blockquote class="fragment"><p>The bane of my existence
	      is doing things I know the computer could do for
	      me.</p><footer>&mdash; <a href="http://www.nature.com/nature/webmatters/xml/xml.html">Dan
                Connolly</a></footer>
	  </blockquote>
	  
	  <aside class="notes">
	    <ul>
	      <li>Motivate also from some real-life problems</li>
	      <li>Things that should fit together, like the CPU and
                RAM to a motherboard, ingredienses of a dish, to
		complex things like building a house.</li>
                <li>Now, you can usually find the data, but connecting
		it you have to do in your head.</li>
	      <li>I have to agree with Connolly's Lament:</li>
	    </ul>
	  </aside>
	</section>
	
	<section>
	  <h3>Technology Adoption</h3>
	  
	  <ul>
	    <li>Hypermedia</li>
              <li>TODO: Code that is made to live beyond the project</li>
	    <li>TODO: Practices that could make development easier.</li>

	  </ul>
	  
            <aside class="notes">
	    <ul>
	      <li>Semweb will not be realised by academia alone, nor
		by industry. No such common platform has succeeded
		without broad develop adoption.</li>
	      <li>Hypermedia is often thought of as a movie embedded
		in text, but the essense is that everything needed in
		the interaction should be accessible in the
		messaging. With human users, it is obvious. 
		Only very primitives may not</li>
	      
	    </ul>
	  </aside>
	  
	</section>
	
	<section>
	  <h3>Make the infrastructure more robust</h3>
	  
	  <ul>
	    <li class="fragments">Research technologies to reject heavy queries</li>
	    <li class="fragments">Create marketplace based query systems</li>
	    <li class="fragments">Find a better client-server balance</li>
	    <li class="fragments">Exploit other infrastructure, such as caching
              proxies</li>
	  </ul>
	  
	  <aside class="notes">
	    <ul>
	      <li>Query answering is needed for both the social and
		practical problems</li>
                <li>Many solutions have been developed to query open
		data sources on the Web, but stability is insufficient
                  for most practical uses.</li>
	    </ul>
	  </aside>
	</section>
	
	<section>
	  <h3>Empirical Evaluations</h3>
	  
	  <ul>
	    <li class="fragment">The community is strong at
              formalizing, and formal results can be evaluated by
	      formal methods</li>
	    <li class="fragment">However, a database system is so
	      complex, it must be evaluated chiefly by empirical
	      methods</li>
	    <li class="fragment">Yet, I found empirical methods in
              its infancy.
	      <ul>
		<li>Few formal hypothesis tests (not even a <i>p</i>-value)</li>
		<li>Unwillingness to dive into statistics</li>
		<li>Benchmarks that do not meet basic standards</li>
	      </ul>
	    </li>
	  </ul>
	  


	  <aside class="notes">
	    <ul>
	      <li>However, I do not consider developing software, nor
                the social implications, nor the contributions to
		caching the main scientific contributions.</li>
	      <li>Rather, I'm motivated to improve empirical
                evaluations</li>
	      <li>But the external validity is always contestable</li>
	      <li>Has many historical parallels, Tycho Brahe
                considered the solar system complex</li>
	      <li>They do not go unchallenged, but abandoning them
		seems a stretch</li>
              </ul>
	  </aside>
	</section>
	
        <section>
          <h3>Also Industry Problem</h3>
          
          <blockquote><p>
              The energy needed to refute benchmarks is
              multiple orders of magnitude bigger than to run them
            </p><footer>&mdash; Brendan Gregg, Netflix</footer>
          </blockquote>
          
          <aside class="notes">
            <p>Systematic approach to evaluate systems, as well as their
              evaluation is needed both for science and for
              industry</p>
          </aside>
        </section>


	<section>
	  <h2>Results</h2>
	  
	  
	  <aside class="notes">
	    I'll briefly go through some of the results
	  </aside>
	</section>
	
	<section>
	  <h3>Read Write Hypermedia</h3>
	  
	  <p>Think of RDF triples as natural language</p>
	  <div class="fragment">
	    <p>Adding triples:</p>
	    <pre>&lt;&gt; hm:canBe hm:mergedInto .</pre>
	    <p class="fragment">Indicates that
	      an <a href="http://www.w3.org/TR/rdf-mt/#graphdefs"
		class="">RDF Merge</a> of payload into the resource should
	      be done.</p>
	  </div>
          
	  <aside class="notes">
	    
	  </aside>
	</section>
	<section>
	  <h3>Self-description</h3>
	  
	  <pre>
	    hm:mergedInto 
	    rdfs:comment "Perform an RDF merge of payload into resource"@en ;
	    rdfs:seeAlso [ 
	    rdfs:label "RDF Merge" ;
	    rdfs:isDefinedBy &lt;http://www.w3.org/TR/rdf-mt/#graphdefs&gt; . 
	    ] .
	  </pre>
	  
            <aside class="notes">
	    
	  </aside>
	</section>
	<section>
	  <h3>Hypermedia Factors</h3>
	  
          <table style="float: none; font-size: 120%" class="hfactors">
	    <thead>
	      <tr>
		<th colspan="5"><a href="http://amundsen.com/hypermedia/hfactor/" title="Hypermedia Factors" class="hfactor-link">Hypermedia Factors</a></th>
	      </tr>
	    </thead>
	    <tbody>
	      <tr>
		
		<td></td>
		<td></td>
		<td class="border cd">CL</td>
		<td></td>
		<td></td>
	      </tr>
	      <tr>
		<td></td>
		
		<td class="border">CR</td>
		<td class="border cd">CU</td>
		<td class="border cd">CM</td>
		<td></td>
	      </tr>
	      <tr>
		<td class="border">LE</td>
		
		<td class="border ld">LO</td>
		<td class="border ld">LT</td>
		<td class="border ld">LN</td>
		<td class="border ld">LI</td>
	      </tr>
	    </tbody>
	  </table>
          <aside class="notes">

          </aside>
	</section>
	
	<section>
	  <h3>Pushing Complexity Down the Stack</h3>
	  
	  
	  <aside class="notes">
	    
	  </aside>
	</section>
	
	<section>
	  <h3>Survey of HTTP Caching Implementations</h3>
	  
	  <h4>Gathering hosts</h4>
	  
	  <p>To decide where to go, we used:</p>
	  <ul>
	    <li><a href="http://lov.okfn.org/">Linked Open
		Vocabularies</a></li>
	    <li><a href="http://prefix.cc/"><tt>prefix.cc</tt></a></li>
	    <li><a href="http://sparqles.ai.wu.ac.at/">SPARQLES
		survey</a></li>
	    <li><a href="http://km.aifb.kit.edu/projects/btc-2014/">Billion
		Triples Challenge 2014</a></li>
	  </ul>
	  
	  
	  <p class="fragment visible"><strong>Got a list of 3117 unique hosts, and
	      did 7745 HTTP requests</strong></p>
	  
	  <aside class="notes">
	    <p>Amongst these, the BTC-2014 is by far the largest, with
              4 GTriples, it represents the breadth, the others are
              small curated datasets.</p>
	    <p>Then the data was scanned with a combination of Perl,
              UNIX grep with fair amounts of manual inspection done</p>
              <p><strong>Go right</strong></p>  
	  </aside>
	  <aside class="notes">
	    
	  </aside>
	</section>
	
	
	<section>
	  <h3>Analysis</h3>
	  
	  <ol>
	    <li>Distribution of freshness lifetime
              <ol>
                <li>Standards-compliant</li>
                <li>Simple heuristic</li>
              </ol>
              </li>
	    <li>Dublin Core properties</li>
	    <li>Do certain server implementations provide better
              caching support than others?</li>
	    <li>Cache (re)validation</li>
	  </ol>
	  
	  <aside class="notes">
	    <p>Focused on descriptive statistics, how frequent
              caching headers are found, how long freshness lifetimes
              are, ease of finding heuristics, possible to
              revalidate</p>
	    <p>We also do statistical hypotheses tests using
              so-called contingency tables</p>
	  </aside>
	</section>
	
	<section>
	  <h3>Standards-compliant caching in numbers</h3>
	  
	  <ul>
	    <li><strong>405</strong> resources returned parsable cache
              headers</li>
	    <li class="fragment"><strong>114</strong> did so to
              prohibit caching</li>
	    <li class="fragment"><strong>3</strong> contained
              conflicting headers</li>
	    <li class="fragment">Usually <tt>Cache-Control</tt> and
              <tt>Expires</tt> both occurred, former most common.</li>
	    <li class="fragment"><strong>269</strong> used
              <tt>Cache-Control</tt> for other purposes than freshness lifetime</li>
	  </ul>
	  
	  
	  <aside class="notes">
	    <p>Look at level of support</p>
	    <p>Reminder: Expires or Cache-Control with max-age</p>
	    <p>Cache-Control to mandate revalidation, prohibition,
              only private caches may use the response, etc.</p>
	  </aside>
	  
	</section>
	
	<section>
	  <h3>Standards-compliant freshness lifetime</h3>
	  
	  <figure>
	    <img src="http://folk.uio.no/kjekje/2015/hardall.png" alt="Standards-compliant
	      freshness lifetime">
	  </figure>
	  
	  <aside class="notes">
	    <ul>
	      <li>Barplot: horizontal axis is divided up unevenly,
                in time bins, 1-59 sec, 60-3599 sec, etc. To make it
                clear, I chose the lesser evil, <a href="http://www.scientificamerican.com/article/experts-time-division-days-hours-minutes/">blame
		  the egyptians and babylonians</a>.</li>  <li>vertical axis
                is the number of times a certain freshness lifetime
                was found.
	      </li>
	      <li>Cache prohibition is most common. Minutes to days
                also common.</li>
	    </ul>
	  </aside>
	  
	</section>
	
	<section>
	  <h3>Standards-compliant freshness lifetime</h3>
            
	  <figure>
	    <img src="http://folk.uio.no/kjekje/2015/hardtable.png" alt="Standards-compliant
	      freshness lifetime">
	  </figure>
	  
	  <aside class="notes">
	    <ul>
	      <li>Breaking up by type: vocabs (light orange),
                generic resources (dark orange), datasets (dark
                violet), SPARQL endpoints (light blue)</li>
	      <li>Width of column proportional to occurances.</li>
	      <li>Height of boxes proportional to category
                abundance</li>
	      <li>Endpoints are in the minutes.</li>
	      <li>Datasets are prohibited. Bad idea: Costly to
                compute. Void is estimates</li>
	      <li>Very little beyond days.</li>
	      <li>Quite different distribution for different
                types. Contigency table can be used, even if a little
                contrived, p-value = 0.00001</li>
	    </ul>
	  </aside>
	</section>
	
	
	<section>
	  <h3>Simple heuristic freshness lifetime</h3>
	  
	  <figure>
	    <img src="http://folk.uio.no/kjekje/2015/heuristicall.png" alt="Simple heuristic
	      freshness lifetime">
	  </figure>
	  
	  <aside class="notes">
	    <ul>
	      <li>Found simple heuristic freshness for 554
                resources. Many more than standards-based. Based on
                actual modification times</li>
	      <li>Now 60% is in the month range. Agreeing with
                Dynamic Linked Data Observatory</li>
	      <li>We could also still verify 911 resources where
                last-modified and/or Etag that were recorded by the
                BTC crawl months prior to our crawl as fresh.
	      </li>
	      <li>This gives a better picture of the actual change
                frequency</li>
	    </ul>
	  </aside>
	  
	</section>
	
	<section>
	  <h3>Simple heuristic freshness lifetime</h3>
	  
	  <figure>
	    <img src="http://folk.uio.no/kjekje/2015/heuristictable.png" alt="Simple heuristic
	      freshness lifetime">
	  </figure>
	  
	  <aside class="notes">
	    <ul>
	      <li>First note that the types are rather similar,
                confirmed by test p = 0.02, still quite different</li>
	      <li>Just one endpoint had last-modified, could be that
                DBMSes aren't helping in tracking</li>
	    </ul>
	  </aside>
	  
	</section>
	
	<section>
	  <h3>Conclusions from the survey</h3>
	  
	  <ul>
	    <li><strong>We found moderate uptake for HTTP caching and
		conditional requests</strong></li>
	    <li class="fragment">Many resources change slowly, but
              standard-compliant cache doesn't reflect this</li>
	    <li class="fragment">Errors are common, but not in caching headers</li>
	    <li class="fragment">Possible to compute heuristic
              freshness from headers or Dublin Core in many cases</li>
	    <li class="fragment">Conditional requests seldomly
              supported on SPARQL endpoints, but standards-compliant
              freshness lifetimes have been seen</li>
	  </ul>
	  
	</section>
	
	<section>
	  <h3>Starting From Basic Principles in Statistics</h3>
	  
	  <h4>Design of Experiments</h4>

	  <ul>
	    <li class="fragment">an experimental setup using DoE.</li>
	    <li class="fragment">how the analysis pointed out the important effects.</li>
	    <li class="fragment">how we got a comprehensive view of the experiment.</li>
	    <li class="fragment">how hypothesis tests could be formulated.</li>
	    <li class="fragment">how 2-level experiments can determine significant effects, even though it is not
	      good enough for modelling.</li>
	    <li class="fragment">how more economic experiments can be designed, and noted their limitations.</li>
	    <li class="fragment">finally how the experiment could be
              shown to be flawed.</li>
	  </ul>
	  
	  
	  <aside class="notes">
	    <ul>
	      <li>Benchmarking is not a scientific experiment,
		merely an engineering tool</li>
	      <li>Focus is didactical</li>
	      <li>Show how to build an experiment from basic
                principles</li>
	      <li>but also to show that the experiment is
                flawed</li>
	    </ul>
	  </aside>
	</section>
	
        
        <section>
          <h2>Starting From Even More Basic Principles</h2>
	  
          <h3>Philosophy of Science</h3>
	  
	  <aside class="notes">
            If you wondered why I didn't take a principled approach to
            the cost model, here's your answer: It is grounded in
            epistemology, in the natural scientist's mind, knowledge
            is founded on the evaluation. Therefore, the focus on my
            effort was reusability, the code is modularized and
            reusable. The evaluation would also be reusable, and
            the cost model done with someone better equipped than
            myself.
          </aside>
        </section>



<!--
        <section>
          <h3></h3>
          
          
          <aside class="notes">

          </aside>
        </section>
-->

        <section>
          <h2>Conclusions</h2>
          <ul>
            <li class="fragment">Hypermedia is one key to developing
            applications on the Semantic Web.</li>
            <li class="fragment">Traits ease the task of developing
              experimental systems and usage of opti- misations in
              underlying systems.
            </li>
            <li class="fragment">While the adoption of caching and
              conditional requests as defined in HTTP is not
              widespread, the adoption is sufficient to start using
              them in practical systems.
            </li>
            <li class="fragment">Evaluation methodologies suffer from
              a poor foundation in philosophy of science, and research
              into the epistemology of the field is important.
            </li>
            <li class="fragment">The author admits that the study is
              lacking in terms of objectivity, but notes that the
              problems are of a general nature.
            </li>
            <li class="fragment">Statistical Design of Experiments
              provides a path to a critical practice of evaluations,
              needed to improve the foundations of the field.
            </li>
          </ul>

          
          <aside class="notes">

          </aside>
        </section>

        <section>
          <h3>Thanks</h3>
        </section>

      </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>
    
    <script>
      
      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: true,
      progress: true,
      history: true,
      center: true,
      slideNumber: true,

      
      transition: 'slide', // none/fade/slide/convex/concave/zoom
      
      // Optional reveal.js plugins
      dependencies: [
      { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
      { src: 'plugin/zoom-js/zoom.js', async: true },
      { src: 'plugin/notes/notes.js', async: true }
      ]
      });
      
    </script>
    
    <script>//<![CDATA[
    document.write('<script src="//' + (location.hostname || 'localhost') + ':35729/livereload.js?snipver=1"><\/script>')
    //]]></script>

  </body>
</html>
