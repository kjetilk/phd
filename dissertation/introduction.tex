\chapter{Introduction}

\section{Semantic Web Technology}\label{sec:semwebtech}

The World Wide Web, or just the Web for short, is a well-known global
information space invented by Tim Berners-Lee in 1989, further emerged
in the 1990-ties. It is characterised first and foremost by its
universality, anyone can set up a computer, connect it to the Internet and
start serving data or documents from it, and further adapt it to their purpose. 

The Semantic Web is an extension of the Web that has been under
development since 1997\footnote{The first working group draft of the
  RDF specification is dated 1997-08-01, see
  \url{http://www.w3.org/TR/WD-rdf-syntax-971002/}.}, to extend the
Web with languages for expressing information in a machine processable
form\cite{semwebroadmap}.\todo{citations in intro}

\subsection{Basic technology}

The Semantic Web is built on a number of specifications that has been
developed under the auspices of the World Wide Web Consortium. The
core technology is known as the Resource Description Framework
(RDF). The framework is defined in a suite of specifications, defining
concepts and abstract syntax, semantics, and several concrete
syntaxes.

Conceptually, an RDF statement is a triple, where the terms are a
subject, a predicate and an object. The building blocks for these
triples are literals, blank nodes and Internationalized Resource
Identifiers (IRI). IRIs builds on the familiar URL: Uniform Resource
Locator, informally known as a Web address,
e.g. \url{https://www.w3.org/RDF/} is an address for a document about
RDF. On the Semantic Web, the URL is first generalised to a Uniform
Resource Identifier, URI, that can not only name a document on the
Web, but any resource. A resource can be a physical thing, like a
person, or an abstract thing, like the type of weather at some place
at some time, numbers, strings, etc. Then, URIs are extended to IRIs
to enable the use of any character in them. Literals are strings with
a datatype (denoted by a IRI), and optionally a language tag. Finally,
blank nodes are unnamed nodes. RDF defines which of these building
blocks may be used for what term: The subject may be a IRI or a blank
node, the predicate only a IRI, whereas the object may be a literal,
blank node or IRI.

The use of IRIs makes it possible to view RDF statements as a directed
graph, where the subject IRI is a vertex, the predicate is an edge to
an object vertex\footnote{In general it is more precisely described as a
  partially labelled directed pseudograph with unique node labels}.

For historical reasons, the first syntax that was standardised for RDF
was an syntax based on the tree-structured Extensible Markup Language
(XML). The simplest standardised syntax is known as N-Triples, where
each statement is written on a single line, where each IRI is written
out in full. The basic building blocks of N-Triples has been reused to
create a compact and natural text form syntax, known as Turtle. Turtle
has gained traction, and is well established as a common syntax. A
simple graph expressed in Turtle could be:

\begin{verbatim}
@prefix foaf: <http://xmlns.com/foaf/0.1/>.
@prefix dct:  <http://purl.org/dc/terms/>.

<http://www.kjetil.kjernsmo.net/foaf#me> a foaf:Person ;
    foaf:name "Kjetil Kjernsmo" ;
    foaf:publications <http://folk.uio.no/kjekje/2013/iswc.pdf> .
<http://folk.uio.no/kjekje/2013/iswc.pdf> a foaf:Document ;
    dct:title "Introducing Statistical Design of Experiments to SPARQL Endpoint Evaluation" ; 
    dct:creator <http://www.kjetil.kjernsmo.net/foaf#me>, 
                <http://data.semanticweb.org/person/john-s-tyssedal> .
\end{verbatim}

The example opens with prefix declarations, to allow abbreviating
IRIs, e.g. the predicate \rdfterm{foaf:name} is an abbreviation of the
IRI \rdfterm{http://xmlns.com/foaf/0.1/name}. The IRI
\rdfterm{http://www.kjetil.kjernsmo.net/foaf\#me} is a name for this
author. The \rdfterm{a} predicate is standards-defined abbreviation
for \rdfterm{http://www.w3.org/1999/02/22-rdf-syntax-ns\#type}, which
is used for declaring the subject an instance of a class, in this case
\rdfterm{foaf:Person}. Then, the \rdfterm{foaf:publications} predicate
is used to link to an author-published version of one of the
publications of this dissertation, and further information is then
provided about this publication, including a link to the co-author. As
we see, semicolons are used to separate statements that share a
subject, commas separate statements with the same subject and
predicate, while periods terminate a statement. 

Note that all the IRIs uses the HTTP schema. The Hypertext Transfer
Protocol (HTTP) is the main application protocol used on the Internet
for the Web, and is also the protocol used most for the Semantic
Web. It is a request-response protocol in a client-server computing
model, but also accommodates for intermediate proxies. HTTP messages
consist of a header, typically with metadata, and a body, which is the
content itself. The standard defines several headers that can be used
to control caching on either the client, the server or an intermediate
proxy.

Also, note that all IRIs in this example are \emph{dereferenceable},
meaning that if an HTTP client is used, a representation of the
resource can be retrieved across the Internet. This, along with that
it is expressed as RDF, makes the above so-called Linked Data.

\subsection{Interacting With Data}

To read and write this graph, several techniques have been
developed. For reading, one is to simply parse the string into a
suited data structure and use any tool available in the chosen
programming language to examine the data structure, or simply write
data to e.g. a Turtle string.

A more sophisticated approach is to match parts of the graphs using
\emph{triple patterns}. A triple pattern may contain variables for
certain terms, for example:

\begin{verbatim}
?subject a ?class .
\end{verbatim}
This triple pattern will match the two triples 
\begin{verbatim}
<http://www.kjetil.kjernsmo.net/foaf#me> a foaf:Person .
<http://folk.uio.no/kjekje/2013/iswc.pdf> a foaf:Document .
\end{verbatim}
from the above example (prefixes omitted for brevity). Frameworks in
popular programming languages commonly have a method that implements
this.

The triple pattern is also a fundamental building block of the SPARQL
query language, which is the language that is the main topic of this
dissertation. SPARQL is an extensive, standardised query language with
both read and write operations. The syntax is near Turtle, but as the
above triple patterns, introduces variables. A set of triple patterns
may be used to create a conjunctive query, and along with a filter
that can be used to further constrain the query with boolean
expressions. Together, they are known as a Basic Graph Pattern
(BGP). More advanced parts of the language is built around BGPs.

SPARQL also introduced a mechanism for naming a graph or parts of a
graph with a IRI, an approach that was subsequently adopted by
RDF. Today, RDF is not just a triple, but may be a quad.

To execute a query, a SPARQL engine would typically parse the query to
create a tree of algebra objects (in the case where an object oriented
programming language is used) in the process. Then, a query planner
component would traverse the algebra tree, and for each algebra object
or branch of algebra objects, the query planner finds various ways to
access the data in the underlying store or execute other
operations. In many programming frameworks, the only way to access
data is through matching a triple pattern. If that is the case and
the incoming query consists of just a BGP, the query planner's task
would simply be to match all the triple patterns and join their
results, and finally apply any constraining filters. 

However, even though the result does not depend on the order of
execution, the time it takes to find the result often does. For
example, consider the following BGP:
\begin{verbatim}
?subject foaf:name ?name ;
         foaf:workplaceHomepage <http://example.com/> ;
         foaf:made ?contribution .
\end{verbatim}
In most cases, if the triple pattern with the \rdfterm{foaf:name}
predicate is evaluated first, it is likely to match many resources,
since nearly everything may have a name, and therefore, it does not
reduce the number of statements that needs to be searched when
matching the next triple pattern by much. Instead, the
\rdfterm{foaf:workplaceHomepage} may be matched first, as we may guess
the fact that the object is given will be more restrictive, but that
too fails if everyone in the database works for the same organisation
and has used this predicate. It is the query planner's task to choose
between equivalent plans to ensure that the most efficient evaluation
is chosen. As is clear from this example, it is often insufficient to
rely on such heuristics, and therefore, it is common to rely on a
statistical digest in the query planner. Still, the task of query
planning remains a very complex one, and often, insufficient
statistics is available, so that planning is done using heuristics or
based on assumptions that do not hold. These are only some of the
concerns that affect performance of the overall query engine.

Indeed, detailed knowledge of the data, such as a comprehensive
statistical digest may be available close to the database, but is not
exposed in ways that higher levels in the technology stack can make
use of. In our case, this is especially true for a caching proxy.

\subsection{Hypermedia}

However, in terms of utility when programming, advanced query
languages such as SPARQL may not be needed for many applications, and
may represent an overly high barrier to entry.

Hypermedia is the idea that all information needed to drive
interaction in an application must be readily available in the
request-response dialogue. For human interactions, this has been
understood as a requirement for a long time, one has to tell the user
how to interact with the application, if not, the user is unlikely to
be able to solve the task. Contemporary efforts now extend this to
machine-machine interactions. 

In this context, hypermedia types is a way to classify what kind of
operations a certain media type can help the application perform.

\section{Contributions}\label{sec:contribsum}

The present work sits in the confluence of several contemporary
efforts in the Semantic Web community. The focus is on query answering
with the SPARQL query language, with emphasis on exploiting the World
Wide Web, but it touches upon query federation, hypermedia, empiricial
methods for evaluating performance, standards compliance and even
philosophy of science. 


\subsection{Hypermedia}

\begin{enumerate}
\item A thorough discussion of the implications of Hypermedia
  Types\cite{hypermediatypes} for RDF.
\item A sketch of a vocabulary for read-write RDF hypermedia.
\end{enumerate}

\subsection{Design of Experiments}

\begin{enumerate}
\item Introduction of a path to critical practice of evaluations, that makes
  use of contemporary statistical techniques, to establish a practice
  that can be used to refute assertions on performance.
\item A didactical experiment to help researchers understand the statistics.
\item The novel application of a well established method in
  statistics, rarely used in Computer Science, to SPARQL endpoint
  evaluation.
  
\end{enumerate}

\subsection{Development problems}

\begin{enumerate}
\item A framework to enable the use of low-level optimisations in
  databases.
\item Simplification when implementing experimental features in
  SPARQL.
\item Novel programming techniques for custom query planners.
\end{enumerate}

\subsection{Survey of HTTP Caching}

\begin{enumerate}
\item An understanding of actual usage of caching headers (metadata)
  on the open Semantic Web.
\end{enumerate}

\subsection{Philosophy of Science}

\begin{enumerate}
\item A provocation to discuss epistemological questions.
\end{enumerate}
