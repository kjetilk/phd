\section{Related work}\label{sec:related}

There is a substantial amount of relevant literature and ongoing
research that is well aligned with the present work, either because
the authors share parts of the motivation, or more serendipitous
reuse.

Verborgh et al. \cite{ldf1} share many of the observations and goals
that motivates this study. They introduce a hypermedia system that can
be used to answer individual triple patterns (known as Triple Pattern
Fragments (TPF)). Their stated goal is to transfer as much as possible
of the burden of evaluating a query from the server to the
client. This can happen because a simple pattern match for a single
triple pattern need not have a SPARQL parser, nor a query
planner. Moreover, the server may materialise responses to frequent
triple patterns and store them in a file system, which can be managed
by a simple Web server. The results may also be paged, so that each
individual response may be kept small. However, TPF mandates that
every response must contain a cardinality estimate for every triple
pattern, an operation that may be quite expensive for the server, and
indeed, this information may be so expensive to provide that SPARQL
planners may not provide it to keep the cost of planning itself
down. In \cite{verborgh2014querying}, they demonstrated SPARQL evaluation over TPF,
and further improvements have been made in more recent papers.

Olaf Hartig has a large number of papers that are adjacent to the
present work, including his Ph.D. dissertation \cite{hartig2014querying} where he
explores querying Linked Data, i.e. query data that is not contained
in an a-priory defined collection of RDF data, but where a resources
are traversed to compute a result. Hartig provides solid formal
foundations for such query processing, as well as computational
feasibility, soundness and completeness. The most relevant paper to
this work is \cite{hartig2011caching}.

Acosta et al. \cite{acosta2014shepherd} has ongoing work named ``SHEPHERD'' to
create a SPARQL processor that takes into account observations done by
the SPARQLES survey \cite{buil2013sparql}, to decompose a SPARQL query into
subqueries that is indicated to be easier for the server to evaluate,
and so is well aligned with our goal to ease the load of the
server. It is not quite clear from the brief description in 
\cite{acosta2014shepherd} whether the SHEPHERD system can cache results locally.

Recently, Papailiou et al. \cite{papailiou2015graph} made an extensive
study of SPARQL caching, addressing some of the same problems as the
present work, except for our emphasis on deployment on proxies in the
Internet and integration with HTTP-based caching.  Montoya et
al. \cite{DBLP:journals/corr/MontoyaSMV15} proposes a query federation
system that takes advantage of client-side data replication. Both
these studies claim to support the entire SPARQL query language, but
in both cases, it is not clear that they actually do that.

Umbrich et al. \cite{umbrich2012hybrid} considered a situation where
parts of the graph changes at different paces. For the slow-changing
parts, they prefetch an entire dataset to a local store to relieve
remote endpoints from some processing, and thereby speed up query
responses. 

Martin et al. \cite{sparqlproxy} implemented a reverse caching proxy
that controlled the changes to the dataset, and so could relieve the
endpoint of the burden of evaluating all queries.

While the approaches are diverse, these studies pull in the same
direction: Motivated by the problems of maintaining SPARQL endpoints,
they all seek to share the burden, and so make query answering
economically feasible.

For more detailed related work, see the corresponding section in the
individual papers.
