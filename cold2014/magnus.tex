\documentclass{llncs}
%\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{cite}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{wrapfig}

\title{Performance of two different ontological and data access methods}
\author{Magn\'{u}s D\ae hlen \and Kjetil Kjernsmo}
\institute{Department of Informatics,
Postboks 1080 Blindern,
N-0316 Oslo, Norway \email{\{magnudae,kjekje\}@ifi.uio.no} }


\subtitle{---Draft submitted to COLD 2014---}


\begin{document}
\maketitle

\begin{abstract}
  We evaluate two different approaches that have been used in the
  literature and in practice by different groups publishing metadata
  about cars when consumed by a prototype application. These
  approaches are characterized by a generic vs. domain specific
  ontology; by a constrained API vs. openly queryable data % TODO:
                                % Magnus, what else
  We have implemented a prototype application where a potential user
  may query selected properties of cars, and we investigate how the
  different choices made by the original designers influence the
  performance of the application. For the evaluation, we employ
  the statistical disipline of Design of Experiments. 

\end{abstract}

\section{Introduction}

The retrieval of information from different sources and then combine
them to allow a user to find a certain combination of properties that
suit their purpose is an archetypical Semantic Web use case. We have
chosen to focus on a product selection use case, specifically on cars,
since some car makers have embraced the Semantic Web vision and chosen
to share detailed data on their products.

The findings, we assert, have a broader validity, given the generic
nature of the problem they are trying to solve, and so our
recommendations should have broad relevance to similar use cases.

We present two different approaches, one promoted by Renault, see
\cite{SemWebAppRes} and \cite{ren1}, and another made by Martin~Hepp
in collaboration with Volkswagen resulting in amongst other things,
the Car Options Ontology~\cite{COO}. We shall compare them to find
their strengths and weaknesses. Each approach contains an ontology and
has its own way of representing data.  To make this comparison we have
used data about the same domain, data about car models and their
component constraints.  The first approach is a generic ontology. By
generic it means that it can be used to represent any product model
with component constraints. The second approach is a domain specific
ontology which as the name implies, is only applicable with one
particular domain. In this thesis that domain is about car models.

We will also show how to create a viable web application which
utilizes such complex data, mainly for the purpose of conducting
performance tests to determine the weaknesses of each approach. This
will be done with complex data found on the web today from different
car manufacturers.  With performance we mean the response time between
a HTTP~\cite{http}} post operation against the application and when
the application presents the user with an answer. The application will
contain the possibility to do HTTP posts against both approaches.

There will be several options on how to query the data because of all
the different specifications.  That is why we have chosen to use the
testing approach \textit{Design of Experiments} (DoE). This approach
will be further explained alongside the results in
Section~\ref{Results}. The evaluation will be based on four
experiments testing several aspects of the approaches. They will help
us determine what kind of factors are significant to the performance.

\section{Related work}
Complex products and specifying configurations has been a research
topic for over a decade.  The possibility to personalize more and more
products is why several research articles have proposed different
approaches on how to handle these configurations. Most of the research
are around finding the ultimate solution with a specification
system. In 1999, M. Aldanondo et. al proposed how to structure a
system to handle configurations and their constraints. This included
proposed definitions for products, configurations and
configurators. The paper focused on making a generic solution to fit
several manufacturers.~\cite{OldConf} In a newer article,
H. Afsarmanesh and M. Shafahi (2013) proposed a complex product
specification system.~\cite{NewConf} This include object modelling and
a user interface. They have focused on supporting stakeholders in the
specification process.

Unfortunately these articles do not present any research done with
semantic technologies. The use of semantic technologies on complex
products is a young field of research. The only thing done here is
what Renault and Volkswagen have presented. Both of these car
manufacturers have presented the public with two different
solutions. They have also shown how to present the data on the web and
the complexity around their solutions.

The Volkswagen solution builds upon GoodRelations, which is a web
vocabulary for e-commerce and was launched in 2008 and is now
widespread. GoodRelations.~\cite{GR} GoodRelations can be used for
detailed information about products to be sold online.

% TODO: Har litt på følelsen at dette blir for tynt for et paper,
% mulig det burde vært mer generelt om Goodrelations, etc. Vi kan jo
% bare se det an.

\section{Evaluation platform}

We set out to evaluate different approaches based on a real use case
where a user is seeking to buy a new car based on detailed data
published by car manufacturers. Today only Renault, of all the car
manufacturers, has opened their data using semantic
technologies. Volkswagen had their data published until the start of
2013, but unfortunately they canceled their Semantic Web project and
the data were removed.  Fortunately, their ontologies are still open
for the community to use. Eventually, we found Daimler very
forthcoming, as they offered data about their A- and B-class cars.
The Daimler data used a custom XML-based format, so we lifted the data
using a Python script into the ontologies developed by Martin Hepp and
Volkswagen.

To be able to put large stress on the application, which again would
allow us to bring out key strengths and weaknesses of the two
different approaches, we chose to create an application where a user
choose several or all car options specifications.

The application was implemented using Apache Maven, Spring and Apache
Tomcat as well as Jena.

The application present users with a web interface where they can
input values for any specification they might want to search for.  In
Figure \vref{initialView} we can see how the application initially
looks for a user. Here the user can input values for the different
specifications, for instance fuel type or CO$_2$ emission. After a
user is done choosing specifications he can execute the actual car
model search. The application extracts the data from the form and
comprises it into another format that can easily be used later on. The
next step begins in the search module. Here it starts a thread for
each possible car model to execute each individual search. In the end
the user is presented with a set of valid models to choose from, which
contain the chosen specifications. In Figure \vref{afterSearch}, we
can see what the user is presented with after a successful query
execution, in this case seventeen different models. In this run, the
user have searched for a model with diesel fuel, automatic
transmission, four or more gears and a maximum of six seats. We also
have the values and URIs for each of these valid models, which means
that the application could present the user with more information than
it does today.

\begin{figure}
  \centering
      \includegraphics[width=12cm]{initialView.png}
  \caption{Initial view for a user}\label{initialView}
\end{figure}

\begin{figure}
  \centering
      \includegraphics[width=12cm]{afterSearch.png}
  \caption{The view after a search}\label{afterSearch}
\end{figure}
There are done some pre-computations to make the application a little
more effective. This includes extracting all the model names from both
ontologies, initiate all possible partially defined products as a
PartialCar object and creating some internal structure. These
pre-computations were done so that it would be possible to present the
user with the name of each car model, not just the URI. We will also
describe more in depth how the car model search is done later on.

% TODO differences between Daimler and Renault

\section{Experiments}\label{Results}

To perform a statistically sound experiment, we turn to techniques
from statistics known as Design of Experiments (DoE). For an
introduction to the use of DoE in Semantic Web research, see~\cite{Kjern}.

\subsection{Planning the experiment}
As other approaches, there are several steps in doing experiments with DoE. 
First one has to state an objective which is important to give the experiment a purpose. 
The next step is to choose a response. The response is the experimental outcome or 
observation. There may be multiple responses in an experiment. In this experiment 
there will be one response and that is the response time on a HTTP post against the application. 
These first two steps are the same for all the experiments in this thesis.

The next two steps of planning an experiment is specific to each experiment itself. This means 
that these steps will be described more in depth in each experiment because it may vary depending on the actual 
experiment. 
The third step in planning an experiment is choosing factors and levels. This is a key part of 
DoE. A factor is a variable that is studied in the experiment, and to be able to study this factor 
it is needed to use two or more values of this factor. These values are referred to as levels. 
This varies from benchmarking because often these levels are not required to do proper benchmarking. 
The levels will allow us the check each factor for its significance. It is important to 
identify the key factors in the planning stage. This is to get the maximum effect out of the experiment. 
Factors may be \textit{quantitative} or \textit{qualitative}. Quantitative factors are often 
numerical values that represent an interval. For instance the weight of a car is considered a 
Quantitative value. Qualitative factors are predefined values within a known set of values. 
In our case a Qualitative factor can be the type of fuel, for instance Diesel. 

The fourth step in planning is to choose the experimental plan. Here we will use one specific approach. The approach 
is called \textit{full factorial experiment} which we will go into more detail about in the next sub-section. There are other 
approaches like fractional factorial experiment, but they were not applicable or relevant to this thesis. 
The last three steps of planning the experiment are performing the experiment, analyzing the output 
and in the end drawing conclusions. More about these steps will be taken individually at each experiment.~\cite{PlanExp}


\subsection{Full factorial experiment}
A full factorial experiment is when one got $k$ factors and $n$ amount of levels. This means 
that there is $n^k$ \textit{factorial designs} which result in $n^k$ designs to execute. 
In the thesis every experiment will only have two levels, but the factors may vary. This means 
that we will use a $2^k$ full factorial design for every experiment. The experiments consist of $2^k$ combinations 
with $k$ factors. For instance if we have three factors where every factor got two levels 
we get $2^3$ designs, also called \textit{runs}. In Table \ref{designs} we can see all 
the possible runs we get from 3 factors. The + and - represent the level for each factor. 
When running the actual experiment one should use a \textit{planning matrix} to display the actual runs in the 
experiment. In Table \ref{designsspec} we can see the same table as before, just that now it is filled out with 
actual factors and their different levels. 

\begin{table}
\begin{center}
    \begin{tabular}{ | l  l  l |}
    \hline
    {\bf Factor 1} & {\bf Factor 2} & {\bf Factor 3} \\ \hline
	 + & + & + \\ \hline
	  - & + & + \\ \hline
	 + & - & + \\ \hline
	  - & - & + \\ \hline
	 + & + & - \\ \hline
	  - & + & - \\ \hline
	 + & - & - \\ \hline
	  - & - &  - \\ \hline
    \end{tabular}
\end{center}
\caption{$2^3$ possible runs}\label{designs}
\end{table}

\begin{table}
\begin{center}
    \begin{tabular}{ | l | l  l  l |}
    \hline
    {\bf Run} &  {\bf Fuel type} & {\bf Transmission} & {\bf Speed} \\ \hline
	 1 & Diesel & Automatic & 100 \\ \hline
	 2 & Petrol & Automatic & 100 \\ \hline
	 3 & Diesel & Manual & 100 \\ \hline
	 4 & Petrol & Manual & 100 \\ \hline
	 5 & Diesel & Automatic & 200 \\ \hline
	 6 & Petrol & Automatic & 200 \\ \hline
	 7 & Diesel & Manual & 200 \\ \hline
	 8 & Petrol & Manual &  200 \\ \hline
    \end{tabular}
\end{center}
\caption{A filled planning matrix with 3 factors}\label{designsspec}
\end{table}

Two key properties of full factorial designs are \textit{balance} and \textit{orthogonality}. 
Balance means that each factor level appears the same amount of times in all the runs. For instance that 
the factor Diesel appears the same amount of runs as Petrol. Orthogonal means that two factors level combinations 
will appear in the same number of runs. As an example will Diesel fuel combined with Automatic transmission 
appear in the same number of runs as Petrol fuel with manual transmission. We can see in Table \ref{designsspec} 
that both these level combinations appear two times. Diesel and automatic appears in run 1 and 5, while Petrol and 
manual appears in run 4 and 8.

Experiments like this can also be replicated, which just means that the experimental plan is run more than one time. 
It is not always efficient to replicate an experiment. Sometimes it can be too expensive to run it more than one time. 
According to Wu and Hamada(2009) replication is unnecessary for computer experiments because repeated computer runs 
with the same input give the same output.
If it is replicated the plan should be randomized to get the best result. One reason for randomizing is to 
identify and get rid of \textit{lurking variables}. A lurking variable is a factor that is not taken into 
account when doing an experiment and that might affect the outcome of the experiment. For instance 
if one is doing an experiment outside. The outdoor temperature might be a affecting the experiment if not taken 
into account.~\cite{FullFac}

\section{Experiments}
In this section we will present several experiments with different amount of factors.
The objective is to find out how the ontologies will perform in comparison and identifying 
which factors affect the outcome of each experiment. We did the ontology alignment and 
development of the application to prevent the loss of precision with either ontology. 

In the experiments the definition for VSO/COO is \textit{-vso} and for CO is \textit{-co}.
These two definitions stand for which ontology are tested in a particular run. In practice this means that when 
we send in the keyword \textit{-vso} we only run the specification search against the car models represented by VSO/COO, 
in our case the data from Daimler. This is referred to 
as the ontology factor in each experiment and is a factor in all the experiments which are presented in 
this thesis. The ontology factor represents the difference in how the data are represented and how the ontologies are 
structures, and with this factor we want to determine how this affects the overall performance. 
We have programmed the application so that the querying of the ontologies are done as similar as possible on both 
levels. This was done to eliminate any interference from the application. There are some 
differences in the programming due that the ontologies were different and they will be discussed later on. 
In Chapter \ref{prototype}, the application and its differences are explained in depth. 

Before starting on the experiment we had to find a way to do the actual experiment. We wanted to 
first create the planning matrix and then execute each run as a HTTP post. To do this we needed to 
make a small script to calculate the $2^k$ runs and perform the HTTP posts. We chose to use 
the programming language \textit{python} to do this. That was because python was a familiar language  
and it also had a package for DoE\footnote{http://pythonhosted.org/pyDOE/}. With the DoE package we just declared 
the amount of factors and the matrix was created. At that point the matrix looked more like Table 
\ref{designs}, which meant that we had to substitute the + and - with the levels of each factor. 
Further in the script we used the package \textit{request}\footnote{http://requests.readthedocs.org/en/latest/} 
to do the HTTP posts in python. Below one can see the line of code executing the request.
\scriptsize\begin{lstlisting}
 r = requests.post('http://localhost:8080/linkedopendata-magnudae/index', 
		  data=payload)
\end{lstlisting}
\normalsize
The \textit{payload} is a dictionary of all the values to post to the application. 
After the request we saved the response which contained the response 
time of a run. After each request we saved the run plus the response time and wrote 
it to file on CSV format. To evaluate the result we used the programming language 
R with the packages \textit{DoE.base}~\cite{DoEBase}, \textit{FrF2}~\cite{FrF2} 
and \textit{BsMD}~\cite{BsMD}. R allowed us to parse 
the CSV files created from the experiments and output them in two types of graphs. 
A similarity with all the experiments were that they all contained at least the factors 
ontology, transmission and fuel type.

To evaluate the graphs we have used a method in the \textit{FrF2} R package called \textit{DanielPlot}. This method assumes that the estimated effects 
are normally distributed with means equal to the effects. The means of all estimated effects are zero. Resulting 
in a plot where the estimated effect would end up on a straight line. This plot is then testing whether all the estimated 
effects have the same distribution. All deviations of the straight line indicates a significant factor. In our results we have 
used the absolute value of the effects, also called a half-normal plot. The advantages of using the half-normal plot is that 
all large estimated effects will end up in the top right corner. This means that the highest performance significance will end up in 
the top right corner.~\cite{Plotting} \\
Here is a quick explanation of the axes shown in each graph. 
The X axis will show the absolute effect of each factor, shown in time. The values on the X axis 
is represented in seconds which means that the a plot will have a significance measured in seconds. 
The Y axis shows the half-normal scores. There are two way of representing the graph and 
that is with either half-normal plots or normal plots. With half-normal the effects on the X 
axis are shown with the absolute effect. This means that all factors are placed with a positive 
half-normal score. This is to avoid visual misleading scores because with the normal scores, deviations from 
the line on negative scores might confuse the reader who are evaluating the charts. 
The scores them selves are a measure for which factor that is the most significant. 
We have also set the \textit{alpha} to $0.05$ which means that we will tolerate a false percentage of $5\%$.

All of the planning matrices, graphs and results will be presented with each experiment later on in this section.
The discussion and interpretation of the results will be presented in Chapter \ref{Discussion}. 
Before starting the experiments we will present abbreviations for each factor because their full name 
made the graphs totally illegible. These abbreviations will be used in the graphs and tables further on in this section. 
The results from all the experiments can be found in appendix \ref{appD}.
\begin{itemize}
  \item Ontology = O
  \item Fuel Type = FT
  \item Transmission = T
  \item Weight = W
  \item Total Weight = WT
  \item Emission = E
  \item Nr. of Gears = G
  \item Seating Capacity = SC
  \item Fuel Consumption = FC
  \item Doors = D
\end{itemize}


  
\subsection{Experiment with three factors}
The first experiment that was done, was the experiment with only three factors. The goal here 
was to see how the ontologies behave with a small amount of querying and factors. 
Table \ref{facandlevExp1} show the different factors and their levels. We chose to start with a 
small experiment using only simple factors which had few possible values. That is why we chose transmission 
and fuel type as factors as well as the ontology factor. With these three factors we got $2^3$ number of runs. 
This meant that we had 8 runs to execute against our application. This experiment was also replicated 
four times to get the most accurate results. The experiment was small so the replication did not cause any issues. 
The results were calculated by finding the average response time for each run between all four replications.

\begin{table}[H]
\begin{center}
    \begin{tabular}{ | l | l l |}
    \hline
    {\bf Factor} & {\bf Level 1} & {\bf Level 2} \\ \hline
	Ontology & -vso & -co \\ \hline 
	Fuel type & Diesel & Unleaded Petrol \\ \hline 
	Transmission & Manual Gearbox & Automatic Gearbox \\ \hline 
    \end{tabular}
\end{center}
\caption{Factors and levels for experiment 1}\label{facandlevExp1}
\end{table}

The next step was to create the planning matrix for this experiment. As mention in the beginning of 
this section we used a package in python to create and fill out the planning matrix. Table \ref{3factor} 
shows all the 8 runs for the experiment with three factors. We also ran a randomized version the experiment to check 
whether the randomization would influence the experiment. The results were almost equal which eliminated randomization as a factor. 
Both results can be found in appendix \ref{appD}. After 
each run the response time were logged to that particular run. The response time were then used to 
check for significant effect when the experiment were evaluated
\begin{table}
\begin{center}
    \begin{tabular}{ | l | l l l |}
    \hline
    {\bf Run} & {\bf Ontology} & {\bf Fuel type} & {\bf Transmission} \\ \hline
	1 & -vso & Diesel & Automatic Gearbox \\ \hline 
	2 & -co & Diesel & Automatic Gearbox \\ \hline 
	3 & -vso & Unleaded Petrol & Automatic Gearbox \\ \hline 
	4 & -co & Unleaded Petrol & Automatic Gearbox \\ \hline 
	5 & -vso & Diesel & Manual Gearbox \\ \hline 
	6 & -co & Diesel & Manual Gearbox \\ \hline 
	7 & -vso & Unleaded Petrol & Manual Gearbox \\ \hline 
	8 & -co & Unleaded Petrol & Manual Gearbox \\ \hline 
    \end{tabular}
\end{center}
\caption{Planning matrix for experiment with three factors}\label{3factor}
\end{table}

Like the rest of the experiments we used DanielPlot to evaluate and 
a package in R to visualize the result. The Figure \vref{3factorGraph} shows the results. 
Here we see no significant factors. Still there are small effects 
from several factors. In Table \vref{3factorEffect} we can see the time effects from largest to smallest. 
We see that the ontology factor has the largest effect on approximately 2.2 seconds which means that one of the 
ontologies overall is 2.2 seconds faster. By reading the results from the linear model it is the factor level 
\textit{-vso} which has an overall faster response time.


\begin{figure}
 \includegraphics[width=12cm]{2factorfinal.pdf}
  \caption{Resulting graph for the three factor experiment}\label{3factorGraph}
\end{figure}

\begin{table}
\begin{center}
    \begin{tabular}{ | l l |}
    \hline
    {\bf Factors} & {\bf Absolute Effect}  \\ \hline
	  O     & 2.2463476\\ \hline
	  O:T    &0.4536135 \\ \hline
	  O:FT:T &0.4534723 \\ \hline
	  T      &0.4513712 \\ \hline
	  FT:T   &0.4499820\\ \hline
	  O:FT   &0.1240831 \\ \hline
	  FT     &0.1189629 \\ \hline
    \end{tabular}
\end{center}
\caption{Table of effects for the three factor experiment}\label{3factorEffect}
\end{table}

\subsection{Experiment with ten factors}
The last experiment we did was a ten factor experiment. The goal 
here was to see which factors would be deemed significant in a complete 
car model search. With the results from this experiment we could discuss 
several aspects of using the different ontologies. 
Here we added 4 new factors in comparison to the six factor experiment. The newly 
added factors were \textit{weight}, \textit{nr. of doors}, \textit{nr. of seats} and 
\textit{fuel consumption}. We used the same approach here as in the previous experiments 
to calculate the average value for the new factors. The average values can be seen in the 
planning matrix in appendix \ref{appB}. With 10 factors the amount of runs were 
$2^10$. This results in 1024 number of runs which made the planning matrix too big to show here. 

In the graph \vref{10factorGraph} we can see the results from running all the 1024 runs.
We can see that there are a lot of significant effects present here. There are more than 
any of the previous experiments, but it is also more factors and factor interactions.
Unfortunately there are so many significant factors that there are some of them that are 
illegible, but most of them have a low impact on the significance graph. Like the six factor experiment we also see 
here that there are three groups of significant factors. The first group where most of them 
are placed range from around 2 seconds effect to 11. Here there are a lot of factor interactions 
and why they are there will be explained in the discussion. 
The second group is very like the second group we saw in the six factor experiment, the only difference is 
that the total weight (WT) factor is substituted with fuel consumption (FC). The last group is 
the same for all the experiments, except the two factor experiment. Here we find the ontology factor. 
In Table \vref{10factorEffect} we can see the top twenty absolute effects. This includes all the 
significant factors from the last group and the second one, but also 5 from the first group. 
We can see that emission also here are present in a lot of the entries, but so is ontology 
as well. The new thing here is the fuel consumption has entered the most significant factors, and 
is by itself higher than emission. The linear model again tells us that the option \textit{-vso} has a significantly lower 
response time than \textit{-co} 

When we accumulated the results from all the runs we ended up with the total 
amount of response time to be approximately 30095 seconds, which is 8 hours, 21 minutes and 35 seconds. 
This were the total response time after running all the runs. This did not take into account all the other 
steps during the experiments which took time, like writing results to file and initiating the application. 
This discouraged the replication of the experiment due to the size and was also a reason why we did not 
do experiments with more factors.




\begin{table}
\begin{center}
    \begin{tabular}{ | l l |}
    \hline
    {\bf Factors} & {\bf Absolute Effect}  \\ \hline
      O & 58.1785542324229 \\ \hline
      E:FC & 45.6971032050781 \\ \hline
      O:E:FC & 45.5502538925781\\ \hline
      FC & 38.6140886777344\\ \hline
      O:FC & 38.5571969433593\\ \hline
      O:E & 35.3967871113281\\ \hline
      E & 35.3827983613282\\ \hline
      O:T & 33.1249425527344\\ \hline
      T & 33.1154579746093\\ \hline
      O:T:E:FC & 29.3077075019531\\ \hline
      T:E:FC & 29.2986405957031\\ \hline
      O:T:FC & 28.2420862089844\\ \hline
      T:FC & 28.2325333808593\\ \hline
      O:T:E & 25.3121093378906\\ \hline
      T:E & 25.3039236347656\\ \hline
      WT:E & 11.9191989902344\\ \hline
      O:WT:E & 11.8908780371094\\ \hline
      O:WT:FC & 11.7234715332032\\ \hline
      WT:FC & 11.7140515488281\\ \hline
      O:D:E & 10.1241599902344\\ \hline
    \end{tabular}
\end{center}
\caption{The top twenty significant effects of the ten factor graph}\label{10factorEffect}
\end{table}


\begin{figure}
 \includegraphics[width=14cm]{10factorAvarageDanielPlot.pdf}
  \caption{Resulting graph for the ten factor experiment}\label{10factorGraph}
\end{figure}



% TODO: In conclusion, discuss external validity.

\end{document}


